{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118611"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/workspace/code/bait_news_gen/data/Fake/content_rotation_forward/filtered/fake_top1_90_99.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>sim_news_content</th>\n",
       "      <th>sim_news_title</th>\n",
       "      <th>filter_bertscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M03_417681</td>\n",
       "      <td>정경두 “SLBM 도발은 남북군사합의에 없다”</td>\n",
       "      <td>정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...</td>\n",
       "      <td>PO_M03_115891</td>\n",
       "      <td>정경두 \\\"北 미사일 발사, '비밀적 도발' 오해\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>북한이 순항미사일을 발사한 지 3일 만인 15일 단거리 탄도미사일 2발을 동해상으로...</td>\n",
       "      <td>한국 첫 SLBM 쏜날, 북 탄도미사일 도발</td>\n",
       "      <td>0.945965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         news_id             original_title  \\\n",
       "0  PO_M03_417681  정경두 “SLBM 도발은 남북군사합의에 없다”   \n",
       "\n",
       "                                    original_content    sim_news_id  \\\n",
       "0  정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...  PO_M03_115891   \n",
       "\n",
       "                      fake_title category  label  \\\n",
       "0  정경두 \\\"北 미사일 발사, '비밀적 도발' 오해\\\"       PO      0   \n",
       "\n",
       "                                    sim_news_content  \\\n",
       "0  북한이 순항미사일을 발사한 지 3일 만인 15일 단거리 탄도미사일 2발을 동해상으로...   \n",
       "\n",
       "             sim_news_title  filter_bertscore  \n",
       "0  한국 첫 SLBM 쏜날, 북 탄도미사일 도발          0.945965  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "# 가설 : 가짜 제목이면 본문에 없는 단어가 포함될 것이다.\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "import re\n",
    " \n",
    "def clean_text(text):\n",
    "  text_removed = re.sub('[-=+,#/\\?:^.@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]', ' ', text)\n",
    "  return text_removed\n",
    "\n",
    "mecab = Mecab()\n",
    "titles = df['fake_title'].tolist()\n",
    "contents = df['original_content'].tolist()\n",
    "\n",
    "title_n_list = []\n",
    "content_n_list = []\n",
    "for idx in tqdm(range(len(titles)), desc=f'Extract Morphs', total=len(titles), leave=False):\n",
    "    title_cleaned = clean_text(titles[idx])\n",
    "    content_cleaned = clean_text(contents[idx])\n",
    "    title_n_list.append([m for m in mecab.morphs(title_cleaned) if len(m) > 1])\n",
    "    content_n_list.append([m for m in mecab.morphs(content_cleaned) if len(m) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = []\n",
    "tokens_for_fakenews = []\n",
    "for title, content in zip(title_n_list, content_n_list):\n",
    "    fake_token = ''\n",
    "    f = 0 #flag for no false negative\n",
    "    for token in title:\n",
    "        # 가설 : 가짜 제목이면 본문에 없는 단어가 포함될 것이다.\n",
    "        content_joined = ' '.join(content)\n",
    "        if content_joined.count(token) == 0:\n",
    "            f = 1\n",
    "            fake_token += token + ' '\n",
    "    if f == 1:\n",
    "        fake.append(1)\n",
    "    else:\n",
    "        fake.append(0)\n",
    "    tokens_for_fakenews.append(fake_token)\n",
    "df['fake'] = fake\n",
    "df['tokens_for_fake'] = tokens_for_fakenews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['fake']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>sim_news_content</th>\n",
       "      <th>sim_news_title</th>\n",
       "      <th>filter_bertscore</th>\n",
       "      <th>fake</th>\n",
       "      <th>tokens_for_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC_M05_227267</td>\n",
       "      <td>대한항공-현대오일뱅크, 바이오항공유 협력 MOU</td>\n",
       "      <td>대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...</td>\n",
       "      <td>EC_M05_232562</td>\n",
       "      <td>대한항공, '바이오항공유' 도입 협력</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>대한항공은 ESG(환경·사회·지배구조) 경영 일환으로 SK에너지와 탄소중립항공유 도...</td>\n",
       "      <td>대한항공, SK에너지와 '탄소중립항공유' 도입 협력</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GB_M11_286727</td>\n",
       "      <td>미국 경제 3분의 1 멈춘다…외출금지령 5개주로 늘어</td>\n",
       "      <td>신종 코로나바이러스 감염증(코로나19) 확산으로 미국 경제 3분의 1이 멈추게 됐다...</td>\n",
       "      <td>GB_M08_299035</td>\n",
       "      <td>美 경제 3분 1 끝...\\\"외출 제한\\\"</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>#1. \\\"외출은 안 됩니다. 어디 갑니까?\\\" 지난달 17일 새벽, 신종 코로나바...</td>\n",
       "      <td>술 마시고 폭행하고…日코로나 확진자 무단 외출에 골머리</td>\n",
       "      <td>0.922919</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LC_M03_094705</td>\n",
       "      <td>[더오래]'젖은 손이 애처로워~' 이제야 그걸 깨닫다니</td>\n",
       "      <td>━ [더,오래] 강인춘의 80돌 아이(27) 작가노트 “엊저녁 식탁에서 우연히 본 ...</td>\n",
       "      <td>LC_M03_094873</td>\n",
       "      <td>[더오래] 대 대 짓거리</td>\n",
       "      <td>LC</td>\n",
       "      <td>0</td>\n",
       "      <td>━ [더,오래] 강인춘의 80돌 아이(14) 작가노트 “인마! 너 마누라 손안에 잡...</td>\n",
       "      <td>마누라에 잡혀사냐고? 천만에 말씀, 사실은…</td>\n",
       "      <td>0.927831</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PO_M08_103716</td>\n",
       "      <td>北, 김정은 사회로 당 전원 회의 돌입…코로나·경제 논의 예상</td>\n",
       "      <td>북한이 이달 상순 개최를 예고한 노동당 중앙위원회 제8기 제5차 전원회의가 8일 시...</td>\n",
       "      <td>PO_M03_113470</td>\n",
       "      <td>北, 제8기 제5차 전원회의 확대회의 개최</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>북한 노동당 중앙위원회 제8기 제5차 전원회의 확대회의가 8일 소집됐다고 조선중앙통...</td>\n",
       "      <td>[속보]北, 노동당 5차 전원회의 확대회의 어제 소집…김정은 참석</td>\n",
       "      <td>0.926741</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LC_M09_365485</td>\n",
       "      <td>영국 두번째 여왕 퀸①-프레디 머큐리의 쇼는 계속된다</td>\n",
       "      <td>[이재익의 아재음악 열전] 드디어 올 것이 왔다.\\n가장 맛있는 사탕을 아껴 먹는 ...</td>\n",
       "      <td>LC_M09_366190</td>\n",
       "      <td>[이재익의 아재음악 열전] 이재익의 아재음악 열전</td>\n",
       "      <td>LC</td>\n",
       "      <td>0</td>\n",
       "      <td>[이재익의 아재음악 열전] 지난여름이었다.\\n퀸과 의 광풍이 불기 전, 아니 미풍도...</td>\n",
       "      <td>20대에 음악으로 세계를 정복한 ‘로켓맨’-엘턴 존①</td>\n",
       "      <td>0.919055</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          news_id                      original_title  \\\n",
       "2   EC_M05_227267          대한항공-현대오일뱅크, 바이오항공유 협력 MOU   \n",
       "7   GB_M11_286727       미국 경제 3분의 1 멈춘다…외출금지령 5개주로 늘어   \n",
       "10  LC_M03_094705      [더오래]'젖은 손이 애처로워~' 이제야 그걸 깨닫다니   \n",
       "13  PO_M08_103716  北, 김정은 사회로 당 전원 회의 돌입…코로나·경제 논의 예상   \n",
       "14  LC_M09_365485       영국 두번째 여왕 퀸①-프레디 머큐리의 쇼는 계속된다   \n",
       "\n",
       "                                     original_content    sim_news_id  \\\n",
       "2   대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...  EC_M05_232562   \n",
       "7   신종 코로나바이러스 감염증(코로나19) 확산으로 미국 경제 3분의 1이 멈추게 됐다...  GB_M08_299035   \n",
       "10  ━ [더,오래] 강인춘의 80돌 아이(27) 작가노트 “엊저녁 식탁에서 우연히 본 ...  LC_M03_094873   \n",
       "13  북한이 이달 상순 개최를 예고한 노동당 중앙위원회 제8기 제5차 전원회의가 8일 시...  PO_M03_113470   \n",
       "14  [이재익의 아재음악 열전] 드디어 올 것이 왔다.\\n가장 맛있는 사탕을 아껴 먹는 ...  LC_M09_366190   \n",
       "\n",
       "                     fake_title category  label  \\\n",
       "2          대한항공, '바이오항공유' 도입 협력       EC      0   \n",
       "7       美 경제 3분 1 끝...\\\"외출 제한\\\"       GB      0   \n",
       "10                [더오래] 대 대 짓거리       LC      0   \n",
       "13      北, 제8기 제5차 전원회의 확대회의 개최       PO      0   \n",
       "14  [이재익의 아재음악 열전] 이재익의 아재음악 열전       LC      0   \n",
       "\n",
       "                                     sim_news_content  \\\n",
       "2   대한항공은 ESG(환경·사회·지배구조) 경영 일환으로 SK에너지와 탄소중립항공유 도...   \n",
       "7   #1. \\\"외출은 안 됩니다. 어디 갑니까?\\\" 지난달 17일 새벽, 신종 코로나바...   \n",
       "10  ━ [더,오래] 강인춘의 80돌 아이(14) 작가노트 “인마! 너 마누라 손안에 잡...   \n",
       "13  북한 노동당 중앙위원회 제8기 제5차 전원회의 확대회의가 8일 소집됐다고 조선중앙통...   \n",
       "14  [이재익의 아재음악 열전] 지난여름이었다.\\n퀸과 의 광풍이 불기 전, 아니 미풍도...   \n",
       "\n",
       "                          sim_news_title  filter_bertscore  fake  \\\n",
       "2           대한항공, SK에너지와 '탄소중립항공유' 도입 협력          0.948480     0   \n",
       "7         술 마시고 폭행하고…日코로나 확진자 무단 외출에 골머리          0.922919     0   \n",
       "10              마누라에 잡혀사냐고? 천만에 말씀, 사실은…          0.927831     0   \n",
       "13  [속보]北, 노동당 5차 전원회의 확대회의 어제 소집…김정은 참석          0.926741     0   \n",
       "14         20대에 음악으로 세계를 정복한 ‘로켓맨’-엘턴 존①          0.919055     0   \n",
       "\n",
       "   tokens_for_fake  \n",
       "2                   \n",
       "7                   \n",
       "10                  \n",
       "13                  \n",
       "14                  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['fake']==0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('/workspace/code/bait_news_gen/data/Real/test.csv')\n",
    "fake_df = pd.read_csv('/workspace/code/bait_news_gen/data/Fake/content_rotation_forward/filtered/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KoBERTScore.KoBERTScore import BERTScore\n",
    "import kss\n",
    "\n",
    "# 제목과 본문내 각 문장 사이의 BERTScore를 구함\n",
    "def get_max_score(df, real=True):\n",
    "    max_score = []\n",
    "    for idx in range(len(df)):\n",
    "        content_sentences = kss.split_sentences(df.loc[idx, 'original_content'])\n",
    "        if real == True:\n",
    "            title_duplicated = [df.loc[idx, 'original_title']] * len(content_sentences)\n",
    "        else:\n",
    "            title_duplicated = [df.loc[idx, 'fake_title']] * len(content_sentences)\n",
    "        bert_scorer = BERTScore(model_name_or_path = 'klue/roberta-large')\n",
    "        score = bert_scorer.score(title_duplicated, content_sentences)\n",
    "        max_score.append(max(score))\n",
    "    df['max_score'] = max_score\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 0/13000 [00:00<?, ?it/s]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02431035041809082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8316d0ae71ae44b9aa06960c185781e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02296280860900879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f927c3ab6a5c4931b27501f9a48e8996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/code/bait_news_gen/filtering/KoBERTScore/KoBERTScore/score.py:418: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  idf = torch.tensor([idf_array]).T\n",
      "Calculate BERTScore:   0%|          | 1/13000 [00:15<56:52:59, 15.75s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023665428161621094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f164cdc6d424c2ca8a1723594688cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021663665771484375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1102e5a7ce9d42089cf68bc6d100a5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 2/13000 [00:26<45:56:16, 12.72s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020867347717285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefaf911d06a409f82a0b91b52d214fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02437305450439453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9a822ab4434da48410d0be584fdf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 3/13000 [00:34<38:55:42, 10.78s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02355051040649414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5c91a72578417ca1138ac346d71b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026172399520874023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93acb058985d4e9e8123fd62e52e7c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 4/13000 [00:43<35:25:13,  9.81s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022922277450561523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c80eff59f7d4ba98d7b05a29e9ea02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029903411865234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e955d8c2a4a66b76441ee6f09d1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 5/13000 [00:50<32:40:28,  9.05s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023009300231933594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b0c3cd59954083ab26fa2dc5e8f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025465965270996094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3613f924cc8467aadf821693c6624c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 6/13000 [00:59<31:46:12,  8.80s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['encoder.layer.18.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.22.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02475142478942871,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Calculating BERTScore",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0141bb2e56b74e91a496782da08048c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating BERTScore:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026871442794799805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Train IDF",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebb886199e04b85b15b97e5405d49be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train IDF: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate BERTScore:   0%|          | 7/13000 [01:06<29:59:10,  8.31s/it]You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/code/bait_news_gen/filtering/test.ipynb 셀 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m real_df \u001b[39m=\u001b[39m get_max_score(real_df)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m fake_df \u001b[39m=\u001b[39m get_max_score(fake_df, real\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/workspace/code/bait_news_gen/filtering/test.ipynb 셀 10\u001b[0m in \u001b[0;36mget_max_score\u001b[0;34m(df, real)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     title_duplicated \u001b[39m=\u001b[39m [df\u001b[39m.\u001b[39mloc[idx, \u001b[39m'\u001b[39m\u001b[39mfake_title\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(content_sentences)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m bert_scorer \u001b[39m=\u001b[39m BERTScore(model_name_or_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mklue/roberta-large\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m score \u001b[39m=\u001b[39m bert_scorer\u001b[39m.\u001b[39mscore(title_duplicated, content_sentences)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313434227d7d/workspace/code/bait_news_gen/filtering/test.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m max_score\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(score))\n",
      "File \u001b[0;32m/workspace/code/bait_news_gen/filtering/KoBERTScore/KoBERTScore/score.py:264\u001b[0m, in \u001b[0;36mBERTScore.__init__\u001b[0;34m(self, model_name_or_path, best_layer, idf_path, rescale_base, device)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m model_name_or_path\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m load_model(model_name_or_path, best_layer)\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrescale_base \u001b[39m=\u001b[39m rescale_base\n",
      "File \u001b[0;32m/workspace/code/bait_news_gen/filtering/KoBERTScore/KoBERTScore/score.py:361\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name_or_path, best_layer)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39melif\u001b[39;00m model_name_or_path \u001b[39min\u001b[39;00m MODEL_TO_BEST_LAYER:\n\u001b[1;32m    360\u001b[0m     tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path)\n\u001b[0;32m--> 361\u001b[0m     encoder \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_name_or_path)\n\u001b[1;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mKo-BERTScore uses only \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(MODEL_TO_BEST_LAYER\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m or local model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCheck `model_name_or_path`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:1325\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwith\u001b[39;00m no_init_weights(_enable\u001b[39m=\u001b[39m_fast_init):\n\u001b[0;32m-> 1325\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m   1327\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# restore default dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:861\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n\u001b[1;32m    860\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings \u001b[39m=\u001b[39m BertEmbeddings(config)\n\u001b[0;32m--> 861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m BertEncoder(config)\n\u001b[1;32m    863\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39m=\u001b[39m BertPooler(config) \u001b[39mif\u001b[39;00m add_pooling_layer \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_weights()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:531\u001b[0m, in \u001b[0;36mBertEncoder.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n\u001b[0;32m--> 531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BertLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mnum_hidden_layers)])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:531\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n\u001b[0;32m--> 531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([BertLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mnum_hidden_layers)])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:456\u001b[0m, in \u001b[0;36mBertLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrossattention \u001b[39m=\u001b[39m BertAttention(config)\n\u001b[1;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate \u001b[39m=\u001b[39m BertIntermediate(config)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m BertOutput(config)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:433\u001b[0m, in \u001b[0;36mBertOutput.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n\u001b[1;32m    432\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(config\u001b[39m.\u001b[39;49mintermediate_size, config\u001b[39m.\u001b[39;49mhidden_size)\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mlayer_norm_eps)\n\u001b[1;32m    435\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(config\u001b[39m.\u001b[39mhidden_dropout_prob)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:90\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 90\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[39m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     init\u001b[39m.\u001b[39;49mkaiming_uniform_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, a\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49msqrt(\u001b[39m5\u001b[39;49m))\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         fan_in, _ \u001b[39m=\u001b[39m init\u001b[39m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/init.py:395\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    393\u001b[0m bound \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m) \u001b[39m*\u001b[39m std  \u001b[39m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49muniform_(\u001b[39m-\u001b[39;49mbound, bound)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_df = get_max_score(real_df)\n",
    "fake_df = get_max_score(fake_df, real=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131999.000000\n",
       "mean          0.928526\n",
       "std           0.015578\n",
       "min           0.816958\n",
       "25%           0.919810\n",
       "50%           0.929679\n",
       "75%           0.938405\n",
       "max           0.999384\n",
       "Name: BERTScore, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BERTScore'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 구간별 count 계산\n",
    "bins = [0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n",
    "labels = ['<[0.9]','[0.9, 0.91]', '[0.91, 0.92]', '[0.93, 0.94]', '[0.94, 0.95]','[0.95, 0.96]', '[0.96, 0.97]', '[0.97, 0.98]', '[0.98, 0.99]', '[0.99, 1]']\n",
    "df['bin'] = pd.cut(df['BERTScore'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "counts = df['bin'].value_counts().sort_index()\n",
    "\n",
    "# barplot 생성\n",
    "counts.plot(kind='bar')\n",
    "plt.xlabel('BertScore')\n",
    "plt.ylabel('Count')\n",
    "plt.title('0.9 ~ 1.0 Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<[0.9]           8454\n",
       "[0.9, 0.91]     19164\n",
       "[0.91, 0.92]    33781\n",
       "[0.93, 0.94]    36798\n",
       "[0.94, 0.95]    20221\n",
       "[0.95, 0.96]     5408\n",
       "[0.96, 0.97]     1505\n",
       "[0.97, 0.98]      530\n",
       "[0.98, 0.99]      199\n",
       "[0.99, 1]          60\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PO', 'IS', 'EC', 'SO', 'LC', 'GB', 'ET'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ET    148\n",
       "LC     25\n",
       "EC     15\n",
       "IS      6\n",
       "SO      3\n",
       "GB      2\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['bin']=='[0.98, 0.99]'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>bait_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>bait_content</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>ET_M03_037031</td>\n",
       "      <td>SMAP 해체설… \\\"기무라 타쿠야만 남고 초난강 외 3명 소속사 떠나\\\"</td>\n",
       "      <td>SMAP 해체설 기무라 타쿠야 초난강 일본의 인기 그룹 ‘스맙(SMAP)’의 해체설...</td>\n",
       "      <td>ET_M03_037029</td>\n",
       "      <td>SMAP 해체설…\\\"기무라 타쿠야만 남고 초난강 외 3명은 소속사 떠나\\\"</td>\n",
       "      <td>ET</td>\n",
       "      <td>0</td>\n",
       "      <td>SMAP 해체설 기무라 타쿠야 초난강 일본의 인기 그룹 ‘스맙(SMAP)’의 해체설...</td>\n",
       "      <td>0.987631</td>\n",
       "      <td>[0.98, 0.99]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>ET_M03_281300</td>\n",
       "      <td>'부탁해요 엄마' 민아, 최태준의 결혼 여부 알아챘다 … 운명의 장난?</td>\n",
       "      <td>'부탁해요 엄마' 민아 '부탁해요 엄마'에서 민아가 최태준이 결혼한 사실을 알았다....</td>\n",
       "      <td>ET_M03_281317</td>\n",
       "      <td>'부탁해요 엄마' 민아, 최태준의 결혼 사실 알아버려 … 운명의 장난</td>\n",
       "      <td>ET</td>\n",
       "      <td>0</td>\n",
       "      <td>'부탁해요 엄마' 민아 '부탁해요 엄마'에서 민아가 최태준이 결혼한 사실을 알았다....</td>\n",
       "      <td>0.981007</td>\n",
       "      <td>[0.98, 0.99]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>ET_M03_279210</td>\n",
       "      <td>\\\"라디오스타\\\" 박소담, '사도' 촬영 중 실제로 맞아 멍들어</td>\n",
       "      <td>박소담 라디오스타 배우 박소담이 MBC '라디오스타'에 출연하여 화제가 되고 있다....</td>\n",
       "      <td>ET_M03_279180</td>\n",
       "      <td>\\\"라디오스타\\\" 박소담, '사도' 촬영 중에 실제로 맞아 멍든 경험</td>\n",
       "      <td>ET</td>\n",
       "      <td>0</td>\n",
       "      <td>박소담 라디오스타 배우 박소담이 MBC '라디오스타'에 출연하여 화제가 되고 있다....</td>\n",
       "      <td>0.983672</td>\n",
       "      <td>[0.98, 0.99]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>ET_M03_280208</td>\n",
       "      <td>'마리와 나' 강호동 서인국, 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"</td>\n",
       "      <td>사진 JTBC 강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다...</td>\n",
       "      <td>ET_M03_280187</td>\n",
       "      <td>강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"</td>\n",
       "      <td>ET</td>\n",
       "      <td>0</td>\n",
       "      <td>사진 JTBC 강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다...</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>[0.98, 0.99]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>ET_M03_279457</td>\n",
       "      <td>김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 공개 '헉'</td>\n",
       "      <td>더불어민주당 소속 김광진 의원실이 ‘응답하라 1988’의 핵심 ‘남편 찾기’와 관련...</td>\n",
       "      <td>ET_M03_279540</td>\n",
       "      <td>김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 논란</td>\n",
       "      <td>ET</td>\n",
       "      <td>0</td>\n",
       "      <td>더불어민주당 소속 김광진 의원실이 ‘응답하라 1988’의 핵심 ‘남편 찾기’와 관련...</td>\n",
       "      <td>0.988083</td>\n",
       "      <td>[0.98, 0.99]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_id                                   original_title  \\\n",
       "1806  ET_M03_037031        SMAP 해체설… \\\"기무라 타쿠야만 남고 초난강 외 3명 소속사 떠나\\\"   \n",
       "3372  ET_M03_281300          '부탁해요 엄마' 민아, 최태준의 결혼 여부 알아챘다 … 운명의 장난?   \n",
       "4515  ET_M03_279210              \\\"라디오스타\\\" 박소담, '사도' 촬영 중 실제로 맞아 멍들어   \n",
       "5240  ET_M03_280208         '마리와 나' 강호동 서인국, 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"   \n",
       "5862  ET_M03_279457  김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 공개 '헉'   \n",
       "\n",
       "                                                content    sim_news_id  \\\n",
       "1806  SMAP 해체설 기무라 타쿠야 초난강 일본의 인기 그룹 ‘스맙(SMAP)’의 해체설...  ET_M03_037029   \n",
       "3372  '부탁해요 엄마' 민아 '부탁해요 엄마'에서 민아가 최태준이 결혼한 사실을 알았다....  ET_M03_281317   \n",
       "4515  박소담 라디오스타 배우 박소담이 MBC '라디오스타'에 출연하여 화제가 되고 있다....  ET_M03_279180   \n",
       "5240  사진 JTBC 강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다...  ET_M03_280187   \n",
       "5862  더불어민주당 소속 김광진 의원실이 ‘응답하라 1988’의 핵심 ‘남편 찾기’와 관련...  ET_M03_279540   \n",
       "\n",
       "                                       bait_title category  label  \\\n",
       "1806    SMAP 해체설…\\\"기무라 타쿠야만 남고 초난강 외 3명은 소속사 떠나\\\"       ET      0   \n",
       "3372       '부탁해요 엄마' 민아, 최태준의 결혼 사실 알아버려 … 운명의 장난       ET      0   \n",
       "4515       \\\"라디오스타\\\" 박소담, '사도' 촬영 중에 실제로 맞아 멍든 경험       ET      0   \n",
       "5240     강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"       ET      0   \n",
       "5862  김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 논란       ET      0   \n",
       "\n",
       "                                           bait_content  BERTScore  \\\n",
       "1806  SMAP 해체설 기무라 타쿠야 초난강 일본의 인기 그룹 ‘스맙(SMAP)’의 해체설...   0.987631   \n",
       "3372  '부탁해요 엄마' 민아 '부탁해요 엄마'에서 민아가 최태준이 결혼한 사실을 알았다....   0.981007   \n",
       "4515  박소담 라디오스타 배우 박소담이 MBC '라디오스타'에 출연하여 화제가 되고 있다....   0.983672   \n",
       "5240  사진 JTBC 강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다...   0.987734   \n",
       "5862  더불어민주당 소속 김광진 의원실이 ‘응답하라 1988’의 핵심 ‘남편 찾기’와 관련...   0.988083   \n",
       "\n",
       "               bin  \n",
       "1806  [0.98, 0.99]  \n",
       "3372  [0.98, 0.99]  \n",
       "4515  [0.98, 0.99]  \n",
       "5240  [0.98, 0.99]  \n",
       "5862  [0.98, 0.99]  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = (df['category'] =='ET') & (df['bin']=='[0.98, 0.99]')\n",
    "df[index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>bait_title</th>\n",
       "      <th>BERTScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>SMAP 해체설… \\\"기무라 타쿠야만 남고 초난강 외 3명 소속사 떠나\\\"</td>\n",
       "      <td>SMAP 해체설…\\\"기무라 타쿠야만 남고 초난강 외 3명은 소속사 떠나\\\"</td>\n",
       "      <td>0.987631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>'부탁해요 엄마' 민아, 최태준의 결혼 여부 알아챘다 … 운명의 장난?</td>\n",
       "      <td>'부탁해요 엄마' 민아, 최태준의 결혼 사실 알아버려 … 운명의 장난</td>\n",
       "      <td>0.981007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>\\\"라디오스타\\\" 박소담, '사도' 촬영 중 실제로 맞아 멍들어</td>\n",
       "      <td>\\\"라디오스타\\\" 박소담, '사도' 촬영 중에 실제로 맞아 멍든 경험</td>\n",
       "      <td>0.983672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>'마리와 나' 강호동 서인국, 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"</td>\n",
       "      <td>강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"</td>\n",
       "      <td>0.987734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 공개 '헉'</td>\n",
       "      <td>김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 논란</td>\n",
       "      <td>0.988083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_title  \\\n",
       "1806        SMAP 해체설… \\\"기무라 타쿠야만 남고 초난강 외 3명 소속사 떠나\\\"   \n",
       "3372          '부탁해요 엄마' 민아, 최태준의 결혼 여부 알아챘다 … 운명의 장난?   \n",
       "4515              \\\"라디오스타\\\" 박소담, '사도' 촬영 중 실제로 맞아 멍들어   \n",
       "5240         '마리와 나' 강호동 서인국, 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"   \n",
       "5862  김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 공개 '헉'   \n",
       "\n",
       "                                       bait_title  BERTScore  \n",
       "1806    SMAP 해체설…\\\"기무라 타쿠야만 남고 초난강 외 3명은 소속사 떠나\\\"   0.987631  \n",
       "3372       '부탁해요 엄마' 민아, 최태준의 결혼 사실 알아버려 … 운명의 장난   0.981007  \n",
       "4515       \\\"라디오스타\\\" 박소담, '사도' 촬영 중에 실제로 맞아 멍든 경험   0.983672  \n",
       "5240     강호동 서인국, '마리와 나' 도도한 고양이에 \\\"우울증 걸릴것 같다\\\"   0.987734  \n",
       "5862  김광진 의원실 \\\"'응답하라 1988' 류준열 결혼식 올리는 중\\\"…스포 논란   0.988083  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['bin']=='[0.98, 0.99]'][['original_title','bait_title','BERTScore']].head() #[['original_title','bait_title','BERTScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
