{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.13.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load Data train | News : 100%|██████████| 39996/39996 [00:02<00:00, 14516.25it/s]\n",
      "Load Data train | Bait : 100%|██████████| 36969/36969 [00:02<00:00, 13155.77it/s]\n",
      "Load Data train | Bait : 100%|██████████| 39996/39996 [00:03<00:00, 12855.55it/s]\n",
      "Load Data validation | Bait : 100%|██████████| 39996/39996 [00:03<00:00, 13104.79it/s]\n",
      "Load Data test | Bait : 100%|██████████| 39996/39996 [00:03<00:00, 12823.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from Fishing.dataset import BaitDataset\n",
    "config = {\n",
    "    'max_word_len': 128,\n",
    "    'bait_path': '/workspace/codes/02_DSBA_Project/bait_news_gen/joonghoon/t5_base/tfidf_content/content_chunking_forward',\n",
    "    'data_path': '/workspace/codes/02_DSBA_Project/bait_news_gen/data/original',\n",
    "    'sort': 'News_Direct',\n",
    "}\n",
    "dataset = BaitDataset(config, split='train', tokenizer=tokenizer)\n",
    "bait_title, news_title, bait_file_path = dataset.load_bait_news_info(data_dir=config['data_path'], bait_dir=config['bait_path'], split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39996, 39996)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bait_title), len(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing BertModel: ['roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.13.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['embeddings.LayerNorm.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.12.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.15.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load klue/roberta-large with 22 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train IDF: 100%|██████████| 40/40 [00:06<00:00,  6.25it/s]t/s]\n",
      "Calculating BERTScore: 100%|██████████| 313/313 [01:27<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "refs = list(news_title.values())\n",
    "cands = list(bait_title.values())\n",
    "from KoBERTScore.KoBERTScore import BERTScore\n",
    "kobertscore = BERTScore(model_name_or_path='klue/roberta-large')\n",
    "score = kobertscore(refs, cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "index = torch.sort(torch.Tensor(score))[1]\n",
    "score = torch.sort(torch.Tensor(score))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9535970091819763\n",
      "Reference: 삼성디스플레이, 최대 10조원 OLED 투자 '스타트'\n",
      "Candidate: 삼성디스플레이, 올해 OLED 설비투자 10조원...2년 연속 뭉칫돈\n"
     ]
    }
   ],
   "source": [
    "index_ = index[-15000]\n",
    "print(f\"Score: {score[index_]}\")\n",
    "print(f\"Reference: {refs[index_]}\")\n",
    "print(f\"Candidate: {cands[index_]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-24 04:42:03.874497: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 04:42:04.755925: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 04:42:04.756013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 04:42:04.756024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313135227d7d/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m refs \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39moriginal_title\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313135227d7d/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m preds \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mbait_title\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313135227d7d/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m bert_scorer \u001b[39m=\u001b[39m BERTScore(model_name_or_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mklue/roberta-large\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313135227d7d/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m score \u001b[39m=\u001b[39m bert_scorer\u001b[39m.\u001b[39mscore(refs, preds)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e313135227d7d/workspace/code/Fake-News-Detection-Dataset/filtering/BertScore.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mBERTScore\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m score\n",
      "File \u001b[0;32m/workspace/code/Fake-News-Detection-Dataset/filtering/KoBERTScore/KoBERTScore/score.py:264\u001b[0m, in \u001b[0;36mBERTScore.__init__\u001b[0;34m(self, model_name_or_path, best_layer, idf_path, rescale_base, device)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m model_name_or_path\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m load_model(model_name_or_path, best_layer)\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrescale_base \u001b[39m=\u001b[39m rescale_base\n",
      "File \u001b[0;32m/workspace/code/Fake-News-Detection-Dataset/filtering/KoBERTScore/KoBERTScore/score.py:361\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name_or_path, best_layer)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39melif\u001b[39;00m model_name_or_path \u001b[39min\u001b[39;00m MODEL_TO_BEST_LAYER:\n\u001b[1;32m    360\u001b[0m     tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path)\n\u001b[0;32m--> 361\u001b[0m     encoder \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_name_or_path)\n\u001b[1;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    364\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mKo-BERTScore uses only \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(MODEL_TO_BEST_LAYER\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m or local model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCheck `model_name_or_path`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:1253\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     archive_file \u001b[39m=\u001b[39m hf_bucket_url(\n\u001b[1;32m   1245\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   1246\u001b[0m         filename\u001b[39m=\u001b[39mfilename,\n\u001b[1;32m   1247\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m   1248\u001b[0m         mirror\u001b[39m=\u001b[39mmirror,\n\u001b[1;32m   1249\u001b[0m     )\n\u001b[1;32m   1251\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 1253\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m   1254\u001b[0m         archive_file,\n\u001b[1;32m   1255\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1256\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1257\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1258\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1259\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1260\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1261\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1262\u001b[0m     )\n\u001b[1;32m   1263\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1264\u001b[0m     logger\u001b[39m.\u001b[39merror(err)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/file_utils.py:1404\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1400\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m   1403\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m-> 1404\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m   1405\u001b[0m         url_or_filename,\n\u001b[1;32m   1406\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1407\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1408\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1409\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1410\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1411\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1412\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1413\u001b[0m     )\n\u001b[1;32m   1414\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m   1415\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/file_utils.py:1574\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m local_files_only:\n\u001b[1;32m   1573\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m         r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mhead(url, headers\u001b[39m=\u001b[39;49mheaders, allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, proxies\u001b[39m=\u001b[39;49mproxies, timeout\u001b[39m=\u001b[39;49metag_timeout)\n\u001b[1;32m   1575\u001b[0m         r\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m   1576\u001b[0m         etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py:102\u001b[0m, in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a HEAD request.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mhead\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from KoBERTScore.KoBERTScore import BERTScore\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "data_path = '../data/Fake/content_chunking_backward/generated/fake_top3.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "refs = df['original_title'].tolist()\n",
    "preds = df['bait_title'].tolist()\n",
    "\n",
    "bert_scorer = BERTScore(model_name_or_path = 'klue/roberta-large')\n",
    "score = bert_scorer.score(refs, preds)\n",
    "df['BERTScore'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake_top3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.basename('../data/Fake/content_chunking_backward/generated/fake_top3.csv').split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '../data/Fake/content_rotation_backward/filtered/fake_top3_90_100.csv'\n",
    "data_path = '../data/Fake/content_rotation_backward/generated/fake_top3.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>bait_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>bait_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M03_417681</td>\n",
       "      <td>정경두 “SLBM 도발은 남북군사합의에 없다”</td>\n",
       "      <td>정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...</td>\n",
       "      <td>PO_M03_108013</td>\n",
       "      <td>정의용 \\\"北 미사일 발사, 9·19 군사합의 위반 없잖아\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS_M10_079706</td>\n",
       "      <td>상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…</td>\n",
       "      <td>올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...</td>\n",
       "      <td>IS_M14_070355</td>\n",
       "      <td>[이슈분석]북한 해킹 파문, \\\"국제 사이버 보안 위협\\\"</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC_M05_227267</td>\n",
       "      <td>대한항공-현대오일뱅크, 바이오항공유 협력 MOU</td>\n",
       "      <td>대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...</td>\n",
       "      <td>EC_M02_005162</td>\n",
       "      <td>대한항공, 도심항공교통 환경 조성 위한 '바이오항공유' 조성</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO_M06_436508</td>\n",
       "      <td>성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상</td>\n",
       "      <td>성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...</td>\n",
       "      <td>SO_M06_129262</td>\n",
       "      <td>성남시, ‘성남박물관' 명칭 선정...제29회 성남시 문화상 선정</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EC_M02_003013</td>\n",
       "      <td>롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달</td>\n",
       "      <td>롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...</td>\n",
       "      <td>EC_M05_246826</td>\n",
       "      <td>롯데하이마트, 해외 에너지 취약계층 아동, 친환경 태양광 랜턴 솔라미 전달</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131995</th>\n",
       "      <td>PO_M08_394777</td>\n",
       "      <td>\\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"</td>\n",
       "      <td>6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...</td>\n",
       "      <td>PO_M08_386027</td>\n",
       "      <td>\\\"국민힘 김은혜· 김동연, 근소한 열세\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131996</th>\n",
       "      <td>SO_M07_155613</td>\n",
       "      <td>울산지검 '공무상 재해보상제도 안내서' 발간해 눈길</td>\n",
       "      <td>울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...</td>\n",
       "      <td>SO_M02_126795</td>\n",
       "      <td>전북, 중대재해 예방·체계 대응 계획 마련</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131997</th>\n",
       "      <td>GB_M11_060449</td>\n",
       "      <td>7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'</td>\n",
       "      <td>인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...</td>\n",
       "      <td>GB_M11_055618</td>\n",
       "      <td>中, \\\"한국서 참전군 유해 송환\\\"</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131998</th>\n",
       "      <td>EC_M05_237797</td>\n",
       "      <td>하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집</td>\n",
       "      <td>하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...</td>\n",
       "      <td>EC_M04_015469</td>\n",
       "      <td>‘하나 소셜벤처 아카데미' 4개 대학 신규 선정</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131999</th>\n",
       "      <td>IS_M10_081282</td>\n",
       "      <td>KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진</td>\n",
       "      <td>KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...</td>\n",
       "      <td>IS_M10_353119</td>\n",
       "      <td>포스코ICT, 산업·산업산업 안전관제 플랫폼 개발</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              news_id                        original_title  \\\n",
       "0       PO_M03_417681             정경두 “SLBM 도발은 남북군사합의에 없다”   \n",
       "1       IS_M10_079706           상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…   \n",
       "2       EC_M05_227267            대한항공-현대오일뱅크, 바이오항공유 협력 MOU   \n",
       "3       SO_M06_436508        성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상   \n",
       "4       EC_M02_003013       롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달   \n",
       "...               ...                                   ...   \n",
       "131995  PO_M08_394777  \\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"   \n",
       "131996  SO_M07_155613          울산지검 '공무상 재해보상제도 안내서' 발간해 눈길   \n",
       "131997  GB_M11_060449  7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'   \n",
       "131998  EC_M05_237797          하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집   \n",
       "131999  IS_M10_081282     KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진   \n",
       "\n",
       "                                                  content    sim_news_id  \\\n",
       "0       정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...  PO_M03_108013   \n",
       "1       올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...  IS_M14_070355   \n",
       "2       대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...  EC_M02_005162   \n",
       "3       성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...  SO_M06_129262   \n",
       "4       롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...  EC_M05_246826   \n",
       "...                                                   ...            ...   \n",
       "131995  6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...  PO_M08_386027   \n",
       "131996  울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...  SO_M02_126795   \n",
       "131997  인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...  GB_M11_055618   \n",
       "131998  하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...  EC_M04_015469   \n",
       "131999  KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...  IS_M10_353119   \n",
       "\n",
       "                                       bait_title category  label  \\\n",
       "0              정의용 \\\"北 미사일 발사, 9·19 군사합의 위반 없잖아\\\"       PO      0   \n",
       "1                [이슈분석]북한 해킹 파문, \\\"국제 사이버 보안 위협\\\"       IS      0   \n",
       "2               대한항공, 도심항공교통 환경 조성 위한 '바이오항공유' 조성       EC      0   \n",
       "3            성남시, ‘성남박물관' 명칭 선정...제29회 성남시 문화상 선정       SO      0   \n",
       "4       롯데하이마트, 해외 에너지 취약계층 아동, 친환경 태양광 랜턴 솔라미 전달       EC      0   \n",
       "...                                           ...      ...    ...   \n",
       "131995                   \\\"국민힘 김은혜· 김동연, 근소한 열세\\\"       PO      0   \n",
       "131996                    전북, 중대재해 예방·체계 대응 계획 마련       SO      0   \n",
       "131997                       中, \\\"한국서 참전군 유해 송환\\\"       GB      0   \n",
       "131998                 ‘하나 소셜벤처 아카데미' 4개 대학 신규 선정       EC      0   \n",
       "131999                포스코ICT, 산업·산업산업 안전관제 플랫폼 개발       IS      0   \n",
       "\n",
       "                                             bait_content  \n",
       "0       정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...  \n",
       "1       한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...  \n",
       "2       대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...  \n",
       "3       성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...  \n",
       "4       롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...  \n",
       "...                                                   ...  \n",
       "131995  국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...  \n",
       "131996  전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...  \n",
       "131997  중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...  \n",
       "131998  중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...  \n",
       "131999  포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...  \n",
       "\n",
       "[132000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13576"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "132000-118424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30800/1348730651.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(df[threshold_under < df['BERTScore'] ][df['BERTScore'] < threshold_upper])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_under = 0.99\n",
    "threshold_upper = 1\n",
    "\n",
    "len(df[threshold_under < df['BERTScore'] ][df['BERTScore'] < threshold_upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30800/1622317083.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[threshold_under < df['BERTScore'] ][df['BERTScore'] < threshold_upper][['original_title', 'bait_title', 'BERTScore']].head()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>bait_title</th>\n",
       "      <th>BERTScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19907</th>\n",
       "      <td>요기요, '다회용기' 카테고리 신설</td>\n",
       "      <td>요기요, '다회용기' 카테고리 신설</td>\n",
       "      <td>0.998862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>무신사, '랩비트 2022' 메인 스폰서 참여</td>\n",
       "      <td>무신사, ‘랩비트 2022' 메인 스폰서 참여</td>\n",
       "      <td>0.992801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20275</th>\n",
       "      <td>‘신사와 아가씨’ 이세희, ‘귀여운 이소룡’ 변신</td>\n",
       "      <td>‘신사와 아가씨’ 이세희, '귀여운 이소룡’ 변신</td>\n",
       "      <td>0.993656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>우주소녀 설아, 서울 억새 온라인 홍보 영상 출연</td>\n",
       "      <td>우주소녀 설아, 서울 억새 온라인 홍보 영상 출연</td>\n",
       "      <td>0.998313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42006</th>\n",
       "      <td>광동제약, '귀한삼 홍삼녹용 발효원' 출시</td>\n",
       "      <td>광동제약, '귀한삼 홍삼녹용 발효원' 출시</td>\n",
       "      <td>0.991354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_title                   bait_title  BERTScore\n",
       "19907          요기요, '다회용기' 카테고리 신설          요기요, '다회용기' 카테고리 신설   0.998862\n",
       "19987    무신사, '랩비트 2022' 메인 스폰서 참여    무신사, ‘랩비트 2022' 메인 스폰서 참여   0.992801\n",
       "20275  ‘신사와 아가씨’ 이세희, ‘귀여운 이소룡’ 변신  ‘신사와 아가씨’ 이세희, '귀여운 이소룡’ 변신   0.993656\n",
       "23703  우주소녀 설아, 서울 억새 온라인 홍보 영상 출연  우주소녀 설아, 서울 억새 온라인 홍보 영상 출연   0.998313\n",
       "42006      광동제약, '귀한삼 홍삼녹용 발효원' 출시      광동제약, '귀한삼 홍삼녹용 발효원' 출시   0.991354"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[threshold_under < df['BERTScore'] ][df['BERTScore'] < threshold_upper][['original_title', 'bait_title', 'BERTScore']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26048"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "407*64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data_path = '../data/Fake/content_rotation_backward/filtered/fake_top3_90_100.csv'\n",
    "# tfidf_data_path = '../data/Fake/tfidf/generated/fake_top3.csv'\n",
    "data_path = '../data/Fake/tfidf/filtered/fake_top3_90_99.csv'\n",
    "# data_path = '../data/Real/test.csv'\n",
    "# data_path = '../data/Fake/fake_original.csv'\n",
    "\n",
    "# tfidf_df = pd.read_csv(tfidf_data_path)\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>sim_news_content</th>\n",
       "      <th>sim_news_title</th>\n",
       "      <th>filter_bertscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M03_417681</td>\n",
       "      <td>정경두 “SLBM 도발은 남북군사합의에 없다”</td>\n",
       "      <td>정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...</td>\n",
       "      <td>PO_M03_108013</td>\n",
       "      <td>정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...</td>\n",
       "      <td>정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"</td>\n",
       "      <td>0.942056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS_M10_079706</td>\n",
       "      <td>상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…</td>\n",
       "      <td>올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...</td>\n",
       "      <td>IS_M14_070355</td>\n",
       "      <td>한국 노린 APT공격 징후...10개 액티브X 취약점 이용</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...</td>\n",
       "      <td>한국 노린 APT공격 징후...10개 액티브X 취약점 이용</td>\n",
       "      <td>0.916675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC_M05_227267</td>\n",
       "      <td>대한항공-현대오일뱅크, 바이오항공유 협력 MOU</td>\n",
       "      <td>대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...</td>\n",
       "      <td>EC_M02_005162</td>\n",
       "      <td>대한항공, 도심항공교통 시대 준비 나선다</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...</td>\n",
       "      <td>대한항공, 도심항공교통 시대 준비 나선다</td>\n",
       "      <td>0.915871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO_M06_436508</td>\n",
       "      <td>성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상</td>\n",
       "      <td>성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...</td>\n",
       "      <td>SO_M06_129262</td>\n",
       "      <td>성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...</td>\n",
       "      <td>성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정</td>\n",
       "      <td>0.939672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EC_M02_003013</td>\n",
       "      <td>롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달</td>\n",
       "      <td>롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...</td>\n",
       "      <td>EC_M05_246826</td>\n",
       "      <td>롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...</td>\n",
       "      <td>롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증</td>\n",
       "      <td>0.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129769</th>\n",
       "      <td>PO_M08_394777</td>\n",
       "      <td>\\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"</td>\n",
       "      <td>6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...</td>\n",
       "      <td>PO_M08_386027</td>\n",
       "      <td>김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...</td>\n",
       "      <td>김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답</td>\n",
       "      <td>0.936452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129770</th>\n",
       "      <td>SO_M07_155613</td>\n",
       "      <td>울산지검 '공무상 재해보상제도 안내서' 발간해 눈길</td>\n",
       "      <td>울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...</td>\n",
       "      <td>SO_M02_126795</td>\n",
       "      <td>중대재해법 내일부터 시행...전북도 대응계획 마련</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...</td>\n",
       "      <td>중대재해법 내일부터 시행...전북도 대응계획 마련</td>\n",
       "      <td>0.930591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129771</th>\n",
       "      <td>GB_M11_060449</td>\n",
       "      <td>7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'</td>\n",
       "      <td>인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...</td>\n",
       "      <td>GB_M11_055618</td>\n",
       "      <td>\\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...</td>\n",
       "      <td>\\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조</td>\n",
       "      <td>0.929864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129772</th>\n",
       "      <td>EC_M05_237797</td>\n",
       "      <td>하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집</td>\n",
       "      <td>하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...</td>\n",
       "      <td>EC_M04_015469</td>\n",
       "      <td>중기청 창업선도대학 6곳 신규선정</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...</td>\n",
       "      <td>중기청 창업선도대학 6곳 신규선정</td>\n",
       "      <td>0.910519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129773</th>\n",
       "      <td>IS_M10_081282</td>\n",
       "      <td>KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진</td>\n",
       "      <td>KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...</td>\n",
       "      <td>IS_M10_353119</td>\n",
       "      <td>포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...</td>\n",
       "      <td>포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다</td>\n",
       "      <td>0.940936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129774 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              news_id                        original_title  \\\n",
       "0       PO_M03_417681             정경두 “SLBM 도발은 남북군사합의에 없다”   \n",
       "1       IS_M10_079706           상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…   \n",
       "2       EC_M05_227267            대한항공-현대오일뱅크, 바이오항공유 협력 MOU   \n",
       "3       SO_M06_436508        성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상   \n",
       "4       EC_M02_003013       롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달   \n",
       "...               ...                                   ...   \n",
       "129769  PO_M08_394777  \\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"   \n",
       "129770  SO_M07_155613          울산지검 '공무상 재해보상제도 안내서' 발간해 눈길   \n",
       "129771  GB_M11_060449  7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'   \n",
       "129772  EC_M05_237797          하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집   \n",
       "129773  IS_M10_081282     KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진   \n",
       "\n",
       "                                         original_content    sim_news_id  \\\n",
       "0       정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...  PO_M03_108013   \n",
       "1       올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...  IS_M14_070355   \n",
       "2       대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...  EC_M02_005162   \n",
       "3       성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...  SO_M06_129262   \n",
       "4       롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...  EC_M05_246826   \n",
       "...                                                   ...            ...   \n",
       "129769  6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...  PO_M08_386027   \n",
       "129770  울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...  SO_M02_126795   \n",
       "129771  인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...  GB_M11_055618   \n",
       "129772  하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...  EC_M04_015469   \n",
       "129773  KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...  IS_M10_353119   \n",
       "\n",
       "                                           fake_title category  label  \\\n",
       "0                정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"       PO      0   \n",
       "1                    한국 노린 APT공격 징후...10개 액티브X 취약점 이용       IS      0   \n",
       "2                              대한항공, 도심항공교통 시대 준비 나선다       EC      0   \n",
       "3                      성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정       SO      0   \n",
       "4                         롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증       EC      0   \n",
       "...                                               ...      ...    ...   \n",
       "129769  김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답       PO      0   \n",
       "129770                    중대재해법 내일부터 시행...전북도 대응계획 마련       SO      0   \n",
       "129771             \\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조       GB      0   \n",
       "129772                             중기청 창업선도대학 6곳 신규선정       EC      0   \n",
       "129773                포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다       IS      0   \n",
       "\n",
       "                                         sim_news_content  \\\n",
       "0       정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...   \n",
       "1       한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...   \n",
       "2       대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...   \n",
       "3       성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...   \n",
       "4       롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...   \n",
       "...                                                   ...   \n",
       "129769  국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...   \n",
       "129770  전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...   \n",
       "129771  중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...   \n",
       "129772  중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...   \n",
       "129773  포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...   \n",
       "\n",
       "                                       sim_news_title  filter_bertscore  \n",
       "0                정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"          0.942056  \n",
       "1                    한국 노린 APT공격 징후...10개 액티브X 취약점 이용          0.916675  \n",
       "2                              대한항공, 도심항공교통 시대 준비 나선다          0.915871  \n",
       "3                      성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정          0.939672  \n",
       "4                         롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증          0.943000  \n",
       "...                                               ...               ...  \n",
       "129769  김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답          0.936452  \n",
       "129770                    중대재해법 내일부터 시행...전북도 대응계획 마련          0.930591  \n",
       "129771             \\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조          0.929864  \n",
       "129772                             중기청 창업선도대학 6곳 신규선정          0.910519  \n",
       "129773                포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다          0.940936  \n",
       "\n",
       "[129774 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bait_title': 'fake_title', 'content': 'original_content'}, inplace=True)\n",
    "df.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sim_news_content'] = df['bait_content']\n",
    "# df['sim_news_title'] = tfidf_df['sim_news_title']\n",
    "# df.rename(columns={'bait_title': 'fake_title', 'content': 'original_content'}, inplace=True)\n",
    "# df['sim_news_title'] = df['fake_title']\n",
    "# df.drop('bait_content', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M02_107666</td>\n",
       "      <td>Jeffrey Hollender, 지속가능한 콘돔 개발</td>\n",
       "      <td>20년전 제프리 홀렌더(Jeffrey Hollender)는 아마존산 고무로 만든 콘...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO_M06_454436</td>\n",
       "      <td>GC녹십자그룹, 의료재단 등 계열사 앞세워 해외판로 개척 본격화</td>\n",
       "      <td>녹십자(006280)그룹이 GC녹십자 산하 3개 계열사와 GC녹십자의료재단을 앞세워...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC_M09_360758</td>\n",
       "      <td>‘공간사랑’ 7080 춤꾼들…‘2014 춤판의 틀을 깨라’</td>\n",
       "      <td>머리는 옛 춤을 잊었지만, 몸은 춤을 기억한다.\\n한국현대무용 1세대 춤꾼 이정희(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO_M02_124375</td>\n",
       "      <td>[기획기사] 스마일게이트, 청년의 게임을 향한 희망을 키우다</td>\n",
       "      <td>글로벌 게임 회사인 스마일게이트는 희망스튜디오라는 재단을 설립하여 게임과 관련된 진...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SO_M06_446495</td>\n",
       "      <td>진중권 \\\"'김만배 녹취'는 쉰 떡밥…선거 앞두고 공작\\\"</td>\n",
       "      <td>부산저축은행 불법 대출 사건과 관련, \\\"박영수 변호사와 윤석열 당시 대검 중수부 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>ET_M03_285158</td>\n",
       "      <td>풍선껌 이동욱, 이것이 바로 '츤데레 남사친'…설렘 폭발</td>\n",
       "      <td>풍선껌 이동욱, 이것이 바로 '츤데레 남사친' 이다 배우 이동욱이 '츤데레 남사친'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ET</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>GB_M11_042745</td>\n",
       "      <td>[원유마감]WTI 1.8% 상승…사우디 아람코 CEO 낙관론</td>\n",
       "      <td>국제유가가 올랐다.\\n사우디 아라비아의 석유공사 아람코가 수요 회복을 기대하는 낙관...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>ET_M13_023119</td>\n",
       "      <td>다비치, 바이브 20주년 ‘REVIBE’ 두 번째 음원 ‘사진을 보다가’ 발매</td>\n",
       "      <td>여성 듀오 다비치(DAVICHI)가 재해석한 보컬 듀오 바이브(VIBE)의 ‘사진을...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ET</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>PO_M01_403091</td>\n",
       "      <td>광우병 재발에 조중동 분열증 보도</td>\n",
       "      <td>이명박 정부의 미국 광우병 대처를 놓고 '거짓말' 논란이 증폭되는 가운데 보수언론은...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>PO_M03_396378</td>\n",
       "      <td>\\\"저런 X소리 어떻게 듣나\\\" 장경태, 통합당 발끈하자 \\\"실수했다\\\"</td>\n",
       "      <td>미래통합당은 25일 법제사법위원회 소속 통합당 위원을 겨냥해 장경태 더불어민주당 의...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             news_id                               original_title  \\\n",
       "0      PO_M02_107666               Jeffrey Hollender, 지속가능한 콘돔 개발   \n",
       "1      SO_M06_454436          GC녹십자그룹, 의료재단 등 계열사 앞세워 해외판로 개척 본격화   \n",
       "2      LC_M09_360758             ‘공간사랑’ 7080 춤꾼들…‘2014 춤판의 틀을 깨라’   \n",
       "3      SO_M02_124375            [기획기사] 스마일게이트, 청년의 게임을 향한 희망을 키우다   \n",
       "4      SO_M06_446495             진중권 \\\"'김만배 녹취'는 쉰 떡밥…선거 앞두고 공작\\\"   \n",
       "...              ...                                          ...   \n",
       "39995  ET_M03_285158              풍선껌 이동욱, 이것이 바로 '츤데레 남사친'…설렘 폭발   \n",
       "39996  GB_M11_042745            [원유마감]WTI 1.8% 상승…사우디 아람코 CEO 낙관론   \n",
       "39997  ET_M13_023119  다비치, 바이브 20주년 ‘REVIBE’ 두 번째 음원 ‘사진을 보다가’ 발매   \n",
       "39998  PO_M01_403091                           광우병 재발에 조중동 분열증 보도   \n",
       "39999  PO_M03_396378     \\\"저런 X소리 어떻게 듣나\\\" 장경태, 통합당 발끈하자 \\\"실수했다\\\"   \n",
       "\n",
       "                                        original_content  sim_news_id  \\\n",
       "0      20년전 제프리 홀렌더(Jeffrey Hollender)는 아마존산 고무로 만든 콘...          NaN   \n",
       "1      녹십자(006280)그룹이 GC녹십자 산하 3개 계열사와 GC녹십자의료재단을 앞세워...          NaN   \n",
       "2      머리는 옛 춤을 잊었지만, 몸은 춤을 기억한다.\\n한국현대무용 1세대 춤꾼 이정희(...          NaN   \n",
       "3      글로벌 게임 회사인 스마일게이트는 희망스튜디오라는 재단을 설립하여 게임과 관련된 진...          NaN   \n",
       "4      부산저축은행 불법 대출 사건과 관련, \\\"박영수 변호사와 윤석열 당시 대검 중수부 ...          NaN   \n",
       "...                                                  ...          ...   \n",
       "39995  풍선껌 이동욱, 이것이 바로 '츤데레 남사친' 이다 배우 이동욱이 '츤데레 남사친'...          NaN   \n",
       "39996  국제유가가 올랐다.\\n사우디 아라비아의 석유공사 아람코가 수요 회복을 기대하는 낙관...          NaN   \n",
       "39997  여성 듀오 다비치(DAVICHI)가 재해석한 보컬 듀오 바이브(VIBE)의 ‘사진을...          NaN   \n",
       "39998  이명박 정부의 미국 광우병 대처를 놓고 '거짓말' 논란이 증폭되는 가운데 보수언론은...          NaN   \n",
       "39999  미래통합당은 25일 법제사법위원회 소속 통합당 위원을 겨냥해 장경태 더불어민주당 의...          NaN   \n",
       "\n",
       "       fake_title category  label  \n",
       "0             NaN       PO      1  \n",
       "1             NaN       SO      1  \n",
       "2             NaN       LC      1  \n",
       "3             NaN       SO      1  \n",
       "4             NaN       SO      1  \n",
       "...           ...      ...    ...  \n",
       "39995         NaN       ET      1  \n",
       "39996         NaN       GB      1  \n",
       "39997         NaN       ET      1  \n",
       "39998         NaN       PO      1  \n",
       "39999         NaN       PO      1  \n",
       "\n",
       "[40000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>sim_news_content</th>\n",
       "      <th>sim_news_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M03_417681</td>\n",
       "      <td>정경두 “SLBM 도발은 남북군사합의에 없다”</td>\n",
       "      <td>정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...</td>\n",
       "      <td>PO_M03_108013</td>\n",
       "      <td>정의용 \\\"北 미사일 발사, 9·19 군사합의 위반 없잖아\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...</td>\n",
       "      <td>정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS_M10_079706</td>\n",
       "      <td>상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…</td>\n",
       "      <td>올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...</td>\n",
       "      <td>IS_M14_070355</td>\n",
       "      <td>[이슈분석]북한 해킹 파문, \\\"국제 사이버 보안 위협\\\"</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...</td>\n",
       "      <td>한국 노린 APT공격 징후...10개 액티브X 취약점 이용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC_M05_227267</td>\n",
       "      <td>대한항공-현대오일뱅크, 바이오항공유 협력 MOU</td>\n",
       "      <td>대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...</td>\n",
       "      <td>EC_M02_005162</td>\n",
       "      <td>대한항공, 도심항공교통 환경 조성 위한 '바이오항공유' 조성</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...</td>\n",
       "      <td>대한항공, 도심항공교통 시대 준비 나선다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO_M06_436508</td>\n",
       "      <td>성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상</td>\n",
       "      <td>성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...</td>\n",
       "      <td>SO_M06_129262</td>\n",
       "      <td>성남시, ‘성남박물관' 명칭 선정...제29회 성남시 문화상 선정</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...</td>\n",
       "      <td>성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EC_M02_003013</td>\n",
       "      <td>롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달</td>\n",
       "      <td>롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...</td>\n",
       "      <td>EC_M05_246826</td>\n",
       "      <td>롯데하이마트, 해외 에너지 취약계층 아동, 친환경 태양광 랜턴 솔라미 전달</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...</td>\n",
       "      <td>롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131995</th>\n",
       "      <td>PO_M08_394777</td>\n",
       "      <td>\\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"</td>\n",
       "      <td>6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...</td>\n",
       "      <td>PO_M08_386027</td>\n",
       "      <td>\\\"국민힘 김은혜· 김동연, 근소한 열세\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...</td>\n",
       "      <td>김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131996</th>\n",
       "      <td>SO_M07_155613</td>\n",
       "      <td>울산지검 '공무상 재해보상제도 안내서' 발간해 눈길</td>\n",
       "      <td>울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...</td>\n",
       "      <td>SO_M02_126795</td>\n",
       "      <td>전북, 중대재해 예방·체계 대응 계획 마련</td>\n",
       "      <td>SO</td>\n",
       "      <td>0</td>\n",
       "      <td>전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...</td>\n",
       "      <td>중대재해법 내일부터 시행...전북도 대응계획 마련</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131997</th>\n",
       "      <td>GB_M11_060449</td>\n",
       "      <td>7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'</td>\n",
       "      <td>인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...</td>\n",
       "      <td>GB_M11_055618</td>\n",
       "      <td>中, \\\"한국서 참전군 유해 송환\\\"</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...</td>\n",
       "      <td>\\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131998</th>\n",
       "      <td>EC_M05_237797</td>\n",
       "      <td>하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집</td>\n",
       "      <td>하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...</td>\n",
       "      <td>EC_M04_015469</td>\n",
       "      <td>‘하나 소셜벤처 아카데미' 4개 대학 신규 선정</td>\n",
       "      <td>EC</td>\n",
       "      <td>0</td>\n",
       "      <td>중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...</td>\n",
       "      <td>중기청 창업선도대학 6곳 신규선정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131999</th>\n",
       "      <td>IS_M10_081282</td>\n",
       "      <td>KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진</td>\n",
       "      <td>KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...</td>\n",
       "      <td>IS_M10_353119</td>\n",
       "      <td>포스코ICT, 산업·산업산업 안전관제 플랫폼 개발</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...</td>\n",
       "      <td>포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              news_id                        original_title  \\\n",
       "0       PO_M03_417681             정경두 “SLBM 도발은 남북군사합의에 없다”   \n",
       "1       IS_M10_079706           상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…   \n",
       "2       EC_M05_227267            대한항공-현대오일뱅크, 바이오항공유 협력 MOU   \n",
       "3       SO_M06_436508        성남시, 문화상 수상자 4명 선정…8일 시민의 날 시상   \n",
       "4       EC_M02_003013       롯데하이마트, 조손가정 결연아동에 입학 격려 지원금 전달   \n",
       "...               ...                                   ...   \n",
       "131995  PO_M08_394777  \\\"서울시장 가상 양자대결…오세훈 49.7% 송영길 36.9%\\\"   \n",
       "131996  SO_M07_155613          울산지검 '공무상 재해보상제도 안내서' 발간해 눈길   \n",
       "131997  GB_M11_060449  7m 악어 배 속에서 나온 30대 청년의 두 다리…주민들 '통곡'   \n",
       "131998  EC_M05_237797          하나금융그룹, '하나 소셜벤처 아카데미' 3기 모집   \n",
       "131999  IS_M10_081282     KT, IoT·빅데이터 활용 노후시설 안전 점검 서비스 추진   \n",
       "\n",
       "                                         original_content    sim_news_id  \\\n",
       "0       정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...  PO_M03_108013   \n",
       "1       올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...  IS_M14_070355   \n",
       "2       대한항공이 항공 부문 기후변화에 대응하기 위해 현대오일뱅크와 협력한다.\\n대한항공과...  EC_M02_005162   \n",
       "3       성남시는 ‘제29회 성남시 문화상 수상자’로 교육 부문 김학수(61), 예술 부문 ...  SO_M06_129262   \n",
       "4       롯데하이마트(대표 황영근)가 24일 입학을 기다리고 있는 조손가정 결연아동 33명을...  EC_M05_246826   \n",
       "...                                                   ...            ...   \n",
       "131995  6·1 지방선거에서 국민의힘 서울시장 후보로 나서는 오세훈 현 서울시장이 더불어민주...  PO_M08_386027   \n",
       "131996  울산지방검찰청은 공무원 재해보상법 시행 후 처음으로 「공무상 재해보상제도 안내서」를...  SO_M02_126795   \n",
       "131997  인도네시아령 파푸아의 한 마을에서 악어의 공격을 받고 실종된 30대 청년의 유해가 ...  GB_M11_055618   \n",
       "131998  하나금융그룹은 창업 교육을 통해 사회혁신 창업가를 육성하는 프로그램 '하나 소셜벤처...  EC_M04_015469   \n",
       "131999  KT와 한국시설물안전진단협회가 IoT(사물인터넷), 빅데이터 등 ICT(정보통신기술...  IS_M10_353119   \n",
       "\n",
       "                                       fake_title category  label  \\\n",
       "0              정의용 \\\"北 미사일 발사, 9·19 군사합의 위반 없잖아\\\"       PO      0   \n",
       "1                [이슈분석]북한 해킹 파문, \\\"국제 사이버 보안 위협\\\"       IS      0   \n",
       "2               대한항공, 도심항공교통 환경 조성 위한 '바이오항공유' 조성       EC      0   \n",
       "3            성남시, ‘성남박물관' 명칭 선정...제29회 성남시 문화상 선정       SO      0   \n",
       "4       롯데하이마트, 해외 에너지 취약계층 아동, 친환경 태양광 랜턴 솔라미 전달       EC      0   \n",
       "...                                           ...      ...    ...   \n",
       "131995                   \\\"국민힘 김은혜· 김동연, 근소한 열세\\\"       PO      0   \n",
       "131996                    전북, 중대재해 예방·체계 대응 계획 마련       SO      0   \n",
       "131997                       中, \\\"한국서 참전군 유해 송환\\\"       GB      0   \n",
       "131998                 ‘하나 소셜벤처 아카데미' 4개 대학 신규 선정       EC      0   \n",
       "131999                포스코ICT, 산업·산업산업 안전관제 플랫폼 개발       IS      0   \n",
       "\n",
       "                                         sim_news_content  \\\n",
       "0       정의용 청와대 국가안보실장이 6일 최근 잇따른 북한의 미사일 발사가 9·19 남북군...   \n",
       "1       한국을 노린 지능형지속위협(APT) 공격 징후가 포착됐다.\\n북한으로 추정되는 해커...   \n",
       "2       대한항공이 도심항공교통(UAM, Urban Air Mobility) 시대의 안전 운...   \n",
       "3       성남시는 오는 2025년 상반기 개관을 목표로 수정구 신흥동에 건립 추진 중인 시립...   \n",
       "4       롯데하이마트는 해외 에너지 소외계층 아동들을 위해 친환경 태양광 랜턴 솔라미를 전달...   \n",
       "...                                                   ...   \n",
       "131995  국민의힘 김은혜 경기지사 후보가 더불어민주당 김동연 경기지사 후보를 오차밤위 밖에서...   \n",
       "131996  전북도는 오는 27일 '중대재해처벌 등에 관한 법률' 시행에 따라 중대재해 사전예방...   \n",
       "131997  중국이 2일 한국으로부터 한국전쟁 참전군인 유해를 돌려받고 '영웅의 귀환'이라며 대...   \n",
       "131998  중소기업청은 청년 창업 활성화와 창업 붐 확산을 위해 우수한 창업 인프라와 역량을 ...   \n",
       "131999  포스코 ICT가 제조 및 건설현장의 안전을 지킬 수 있는 스마트 안전관제 플랫폼을 ...   \n",
       "\n",
       "                                       sim_news_title  \n",
       "0                정의용 \\\"北 발사체 도발, 9·19 남북군사합의 위반 아니다\\\"  \n",
       "1                    한국 노린 APT공격 징후...10개 액티브X 취약점 이용  \n",
       "2                              대한항공, 도심항공교통 시대 준비 나선다  \n",
       "3                      성남시, 성남시립박물관 명칭 ‘성남역사박물관’으로 결정  \n",
       "4                         롯데하이마트, 해외 결연 아동에 태양광 랜턴 기증  \n",
       "...                                               ...  \n",
       "131995  김은혜 47.9% vs 김동연 39.4%… 경기도민, 국정안정론에 51.3% 응답  \n",
       "131996                    중대재해법 내일부터 시행...전북도 대응계획 마련  \n",
       "131997             \\\"영웅 돌아왔다\\\"…한국전 전몰자 유해송환 中 애국주의 강조  \n",
       "131998                             중기청 창업선도대학 6곳 신규선정  \n",
       "131999                포스코ICT 안전관제 플랫폼 '제2의 광주 사고' 막는다  \n",
       "\n",
       "[132000 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
