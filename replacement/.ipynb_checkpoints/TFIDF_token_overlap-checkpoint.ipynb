{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from konlpy.tag import Mecab\n",
    "from methods import get_similar_filepath_dict, extract_nouns, extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU \n",
    "    # CUDA randomness\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'datadir' : '/workspace/code/Fake-News-Detection-Dataset/data/Part1',\n",
    "    'savedir' : '../data-saeran',\n",
    "    'METHOD': {\n",
    "        'name'    : 'tfidf_overlap',\n",
    "        'tfidf_target' : 'full', #title, context, full \n",
    "        'query'  : 'context', \n",
    "        'document' : 'full',\n",
    "        'select_name' : 'tfidf_title_category_select',\n",
    "        'topk' : 20,\n",
    "        },\n",
    "    'SEED':42    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_seed(cfg['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update save directory\n",
    "cfg['savedir'] = os.path.join(cfg['savedir'], cfg['METHOD']['select_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file list\n",
    "file_list = glob(os.path.join(cfg['datadir'], 'train/NonClickbait_Auto/EC/*'))\n",
    "save_list = [p.replace(cfg['datadir'], cfg['savedir']) for p in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(file_list: list, target: str = None, join: bool = True) -> List[list]:\n",
    "    \"\"\"\n",
    "    extract nouns from target text\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract morphs\n",
    "    mecab = Mecab()\n",
    "\n",
    "    # define list\n",
    "    nouns_list = []\n",
    "\n",
    "    for file_path in tqdm(file_list, desc=f'Extract Morphs({target})', total=len(file_list), leave=False):\n",
    "        # load source file\n",
    "        source_file = json.load(open(file_path, \"r\"))\n",
    "        \n",
    "        if target == 'title':\n",
    "            text = source_file['sourceDataInfo']['newsTitle']\n",
    "        elif target == 'context': \n",
    "            text = source_file['sourceDataInfo']['newsContent']\n",
    "        elif target == 'full':\n",
    "            text = source_file['sourceDataInfo']['newsTitle'] + source_file['sourceDataInfo']['newsContent']\n",
    "\n",
    "        if join:\n",
    "            nouns_list.append(' '.join(mecab.nouns(text)))\n",
    "        else:\n",
    "            nouns_list.append(mecab.nouns(text))\n",
    "\n",
    "    return nouns_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get TFIDF word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20664"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = cfg['METHOD']['tfidf_target']\n",
    "corpus_list = extract_nouns(file_list, target=corpus)\n",
    "len(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfidfVectorizer().fit(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tokens = tf_idf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49849"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert text to TFIDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "q_target = cfg['METHOD']['query']\n",
    "p_target = cfg['METHOD']['document']\n",
    "\n",
    "query = extract_nouns(file_list=file_list, target=q_target)\n",
    "# documents = extract_nouns(file_list=file_list, target=p_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspace/code/Bait-News-Generation/Fake-News-Detection-Dataset/clickbait_direct/TFIDF_token_overlap copy.ipynb 셀 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f626169742d6e6577732d67656e32222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3136332e3135322e3137362e323338227d7d/workspace/code/Bait-News-Generation/Fake-News-Detection-Dataset/clickbait_direct/TFIDF_token_overlap%20copy.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m documents \u001b[39m=\u001b[39m corpus\u001b[39m.\u001b[39;49mcopy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "documents = corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf = tf_idf_model.transform(query).toarray()\n",
    "document_tfidf = tf_idf_model.transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(query_tfidf, document_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapped Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 290 ms, total: 3.73 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_k = cfg['METHOD']['topk']\n",
    "topkindex = np.argpartition(cos_sim,-top_k, axis=1)[:,-top_k:] #not sorted (argsort보다 속도 훨씬 빠름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Score\n",
    "# # df_result = pd.DataFrame(columns=['index','score','index'])\n",
    "# topkindex_sorted = np.argsort(cos_sim, axis=1)[:,-top_k:]\n",
    "# for idx in topkindex_sorted[0]:\n",
    "#     print(f'index : {idx} score : {cos_sim[0][idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-20 documents by similarity on tfidf vectors\n",
    "# 1. make query's unique token dictionary\n",
    "# 2. sort top-20 documents by # of overlapped token\n",
    "\n",
    "query_ids = range(len(query))\n",
    "token_overlap = dict() #q_id : {d_id : # of overlapped tokens}\n",
    "for q_id in query_ids:\n",
    "    token_overlap[q_id] = {}\n",
    "    topk_docs_ids = topkindex[q_id]\n",
    "    for d_id in topk_docs_ids:\n",
    "        count = len(set(query[q_id]) & set(documents[d_id]))\n",
    "        token_overlap[q_id][d_id] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_overlap_sorted = dict()\n",
    "for q_id, overlap_cnt_dict in token_overlap.items():\n",
    "    token_overlap_sorted[q_id] = dict(sorted(overlap_cnt_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {document id : count} -> [document ids]\n",
    "token_overlap_sorted_idx = [list(d_dict.keys()) for q_id, d_dict in token_overlap_sorted.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis top-k score & token overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token overlapped의 평균 구하기 (top1 ~ top10) : 보통 몇개정도 겹치는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1과 topk중 ovelapped가 가장 많이 된 것이 다른 query의 개수 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_accuracy(query_ids, token_overlap_sorted_idx):\n",
    "    top_1_accuracy = 0.0\n",
    "    for query_id, indices in zip(query_ids, token_overlap_sorted_idx):\n",
    "        if query_id == indices[0]: #query와 document로 사용하는 text가 달라야 유의미함.\n",
    "            top_1_accuracy += 1.0\n",
    "    top_1_accuracy = round(top_1_accuracy/len(query_ids), 5)\n",
    "\n",
    "    top_K_accuracy = 0.0\n",
    "    for query_id, indices in zip(query_ids, token_overlap_sorted_idx):\n",
    "        if query_id in indices:\n",
    "            top_K_accuracy += 1.0\n",
    "            \n",
    "    top_K_accuracy = round(top_K_accuracy/len(query_ids), 5)\n",
    "    return top_1_accuracy, top_K_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP_1 accuracy : 0.99748\n",
      "TOP_10 accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "top_1_accuracy, top_K_accuracy = score_accuracy(query_ids, token_overlap_sorted_idx)\n",
    "print(f'TOP_1 accuracy : {top_1_accuracy}')\n",
    "print(f'TOP_10 accuracy : {top_K_accuracy}') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Function Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_overlap_sim_matrix(corpus: list, query : list, document : list, **kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    make similarity matrix using tfidf similarity\n",
    "    \"\"\"\n",
    "    tf_idf_model = TfidfVectorizer().fit(corpus)\n",
    "    tf_idf_query = tf_idf_model.transform(query).toarray()\n",
    "    tf_idf_document = tf_idf_model.transform(document).toarray()\n",
    "    cos_sim = cosine_similarity(tf_idf_query, tf_idf_document)\n",
    "    \n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_token(cos_sim, query, documents, top_k = None, Train = False):\n",
    "    top_k = top_k\n",
    "    topkindex = np.argpartition(cos_sim,-top_k, axis=1)[:,-top_k:] #not sorted\n",
    "\n",
    "    # top-20 documents by similarity on tfidf vectors\n",
    "    # 1. make query's unique token dictionary\n",
    "    # 2. sort top-20 documents by # of overlapped token\n",
    "\n",
    "    query_ids = range(len(query))\n",
    "    token_overlapped = dict() #q_id : {d_id : # of overlapped tokens}\n",
    "    for q_id in query_ids:\n",
    "        token_overlapped[q_id] = {}\n",
    "        topk_docs_ids = topkindex[q_id]\n",
    "        for d_id in topk_docs_ids:\n",
    "            count = len(set(query[q_id]) & set(documents[d_id]))\n",
    "            token_overlapped[q_id][d_id] = count\n",
    "\n",
    "    token_overlapped_sorted = dict()\n",
    "    for query, cnt_overlapped_dict in token_overlapped.items():\n",
    "        token_overlapped_sorted[query] = dict(sorted(cnt_overlapped_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    if Train == True:\n",
    "        # {document id : count} -> [document ids]\n",
    "        token_overlapped_sorted_idx = [list(d_dict.keys()) for q_id, d_dict in token_overlapped_sorted.items()]\n",
    "        return token_overlapped_sorted_idx\n",
    "    \n",
    "    # masking query_id == documents_id\n",
    "    for query_id, documents in token_overlapped_sorted.items():\n",
    "        if query_id in documents.keys():\n",
    "            documents[query_id] = 0\n",
    "    results = [list(documents.keys())[0] for query_id, documents in token_overlapped_sorted.items()] \n",
    "    results = np.expand_dims(results, axis=1) #[[d_id],[d_id],...,[d_id]]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(cfg, tf_idf_model):\n",
    "    #load validation file\n",
    "    file_list = glob(os.path.join(cfg['datadir'], 'validation/NonClickbait_Auto/EC/*'))\n",
    "    query_ids = range(len(file_list))\n",
    "\n",
    "    #extract nount from query and documents seperately\n",
    "    q_target = cfg['METHOD']['query']\n",
    "    d_target = cfg['METHOD']['document']\n",
    "\n",
    "    queries = extract_nouns(file_list=file_list, target=q_target)\n",
    "    documents = extract_nouns(file_list=file_list, target=d_target)\n",
    "\n",
    "    #get query tfidf and document tfidf\n",
    "    query_tfidf = tf_idf_model.transform(queries).toarray()\n",
    "    document_tfidf = tf_idf_model.transform(documents).toarray()\n",
    "\n",
    "    #calculate similarity\n",
    "    cos_sim = cosine_similarity(query_tfidf, document_tfidf)\n",
    "\n",
    "    #get top-k documents\n",
    "    token_overlapped_sorted_idx = overlap_token(cos_sim, queries, documents, top_k = cfg['METHOD']['topk'], Train = True)\n",
    "\n",
    "    return query_ids, token_overlapped_sorted_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP_1 accuracy : 0.99961\n",
      "TOP_10 accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# top-20 passages by similarity on tfidf vectors\n",
    "# 1. make query's unique token dictionary\n",
    "# 2. sort top-20 passages by # of overlapped token\n",
    "\n",
    "val_query_ids, val_token_overlapped_sorted_idx = validation(cfg, tf_idf_model)\n",
    "top_1_accuracy, top_K_accuracy = score_accuracy(val_query_ids, val_token_overlapped_sorted_idx)\n",
    "print(f'TOP_1 accuracy : {top_1_accuracy}')\n",
    "print(f'TOP_10 accuracy : {top_K_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------title-------------\n",
      "중기부, '2022 메이커 스타' 참가자 모집\n",
      "-------------document-------------\n",
      "CJ온스타일은 15일 상생 프로그램 '챌린지! 스타트업'을 통해 약 3개월의 교육과 평가를 거친 6개 기업을 선발했다고 밝혔다.\n",
      "선발된 기업에게는 CJ온스타일 방송 진출 기회와 함께 상금 총 2억원이 제공된다. '챌린지! 스타트업'은 스타트업에게 사업 경험 전반을 전수하는 CJ온스타일의 대표 상생 프로그램이다.\n",
      "선발된 6개 기업은 단계별 심사와 교육 과정에서 우수성을 입증한 혁신 기술 기반 기업이다.\n",
      "CJ온스타일은 지난 3월 모집한 지원서를 검토해 26개 참가 기업을 1차 선발했다.\n",
      "서울창업허브와 CJ온스타일은 이들 중 필요한 곳에 상품 기획, 브랜딩 경험, 판로 개척 등에 대한 개별 컨설팅과 시제품 제작 서비스 등을 제공했다.\n",
      "이후 4월 말 진행한 데모데이와 다면 평가를 통해 선발 기업이 확정됐다.\n",
      "선발된 기업은 독창적 사업 아이디어와 제품 기술력을 보유했다. '샤플'의 헤어 드라이기는 '가성비 다이슨 헤어 스타일러'라는 별명을 얻을 정도로 스타일링 효과에 대한 평이 좋다. '나인랩'의 텀블러 자외선 살균기는 사용자들이 세척에 불편함을 겪고 있는 점에 착안해 개발됐다. '네츄럴솔루션이엠비씨'는 특정 신체 부위에 음파 자극을 줘 운동효과를 극대화한 제품이다. '더원리빙'의 보온 플레이트와 '플트리스'의 오피스 가드닝 제품, 친환경 운송수단인 '쎄미시스코'의 소형 전기차 EV Z 등도 선발 기업의 대표 제품이다.\n",
      "CJ온스타일은 선발된 6개 기업의 제품을 올해 자사 방송 프로그램에서 선보일 계획이다.\n",
      "판매수수료 없는 중소기업 무료방송'1사1명품’에서 주로 내놓으나 상품 특성과 물량 공급 사정에 맞춰 CJ온스타일 모바일 애플리케이션과 모바일 라이브커머스에서도 판매한다.\n",
      "참여 기업 만족도가 높아 올해 최대 4개 기업을 추가 선발할 계획이다.\n",
      "-------------title-------------\n",
      "이케아 코리아, 지속가능한 소비 돕는 페이백 이벤트 개최\n",
      "-------------document-------------\n",
      "26일부터 코로나19로 인한 소비 부진을 극복하기 위한 대규모 할인행사 '대한민국 동행세일'이 시작된다.\n",
      "전국 주요 백화점과 마트 등 대형 유통업체, 제조업체뿐만 아니라 전통시장, 소상공인, 온라인쇼핑몰 등 다양한 판매자들이 대규모 할인행사에 동참한다.\n",
      "쌍용자동차는 내달 1~31일 모든 차종을 일시불 혹은 할부로 구매하는 고객에게 할인 혜택을 제공한다.\n",
      "구체적인 판매 조건은 6월말 확정된다.\n",
      "금호타이어는 타이어프로 쇼핑몰을 통해 제휴사 임직원에게 타이어를 최대 35% 할인하고, 한국타이어앤테크놀로지는 룰렛 게임을 통해 타이어 추가 증정, 할인쿠폰과 음료교환권, 모바일 주유권 등을 제공하기로 했다.\n",
      "삼성전자, LG전자도 대한민국 동행세일에 함께한다.\n",
      "삼성전자는 으뜸효율 가전제품을 사는 경우 기존 10% 환급 외 추가 혜택을 증정하고, 행사 모델을 구매하는 고객을 대상으로 추첨을 진행해 8K QLED TV, 비스포크 냉장고, 그랑데 AI(인공지능) 건조기 등 경품을 제공한다.\n",
      "LG전자는 올해 상반기 히트 상품으로 구성된 특별전을 열고, 특정 모델을 한정 수량 판매한다.\n",
      "쿠첸은 신제품 밥솥 최대 15% 할인, 으뜸효율 밥솥 최대 30% 할인 등을 진행한다.\n",
      "쿠쿠 또한 트윈프레셔 마스터셰프 6인용 밥솥을 12%를 판매한다.\n",
      "이마트, 이마트 에브리데이, 홈플러스, 롯데마트 등 대형 마트들은 25일부터 내달 1일까지 상품권 증정, 할인 행사 등을 진행한다.\n",
      "롯데백화점, 신세계백화점, 현대백화점 등도 동행세일 기간 동안 협력사 수수료 인하, 중소기업 제품 판매 등을 통해 상생을 도모한다.\n",
      "특히 이들은 오는 26~28일 산업통상자원부가 주최하고, 한국패션산업협회가 주관하는 코리아 패션마켓을 열어 의류와 잡화를 대폭 할인한다.\n",
      "이베이코리아는 G마켓, 옥션, G9를 통해 동행세일에 동참한다.\n",
      "G마켓과 옥션은 모든 회원을 대상으로 '35% 할인쿠폰'을, 멤버십 회원인 스마일클럽에게는 '37% 할인쿠폰'을 각각 제공한다.\n",
      "ID 당 매일 1회씩 증정하며, 행사 상품을 1만5000원 이상 구매할 경우 최대 7000원까지 할인된다.\n",
      "G9는 모든 회원에게 '18% 할인쿠폰'을, 스마일클럽 회원에게는 '20% 할인쿠폰'을 한 장 더 제공한다.\n",
      "ID 당 매일 3회씩 제공된다.\n",
      "이베이코리아는 우수 중소상공인이 판매하는 식품, 패션, 뷰티, 디지털, 가전 생활용품 등을 특가에 선보인다.\n",
      "김해동 이베이코리아 영업기획실장은 미디어SR에 \\\"코로나19로 인해 어려움을 겪고 있는 중소상공인들에게 실질적인 도움을 주자는 취지로 대한민국 동행세일 행사에 동참한다\\\"며 \\\"중소셀러들의 우수한 제품을 엄선해 할인가에 선보이는 만큼 고객들에게도 특별한 쇼핑 기회가 될 것으로 보인다\\\"고 말했다.\n",
      "-------------title-------------\n",
      "규제강화·금리인상에 은행 가계대출 주춤…지난달 2조 증가에 그쳐\n",
      "-------------document-------------\n",
      "한국은행이 기준금리를 기존 0.75%에서 연 1.00%로 0.25%p 인상했다.\n",
      "이로써 지난해 3월부터 시작된 '제로(0)금리' 시대는 1년 8개월 만에 막을 내리게 됐다.\n",
      "초저금리 시대의 마감에 따른 파급효과도 주목된다.\n",
      "대출 차주의 이자 부담, 대출 실수요자 상품의 금리 인상 등의 우려도 제기되지만, 예‧적금 상품의 금리 인상 등 긍정적 효과도 기대할 수 있다는 것이다.\n",
      "특히 금융업계에서는 한국은행과 금융당국이 내년에도 추가 금리 인상이 필요하다는 시그널을 지속적으로 시장에 보내온 만큼, 상반기 내 최대 1.50%까지 금리가 인상될 가능성도 예의주시하고 있다.\n",
      "25일 한국은행(이하 한은)은 25일 오전 금융통화위원회 본회의를 열고 기준금리를 연 1.00%로 인상한다고 밝혔다.\n",
      "한국은행은 지난해 3월 임시 금통위 이후, 약 1년 8개월 만인 지난 8월 금통위에서 0.25%p 금리를 인상했다.\n",
      "그리고 지난 10월 금통위에서는 금리 동결을 선택하며 숨 고르기에 나선 바 있다.\n",
      "다만, 당시 금통위에서도 상당수 금통위원이 기준금리 인상의 필요성을 강조하면서, 올해 마지막 금통위인 오늘 회의에서의 인상 가능성은 그 어느 때보다 높게 점쳐졌다.\n",
      "가계부채‧물가 상승률 억제 효과 기대 한국은행의 이번 제로금리 시대 마감 결정은 역대급 기록을 경신하고 있는 가계부채의 폭증세를 막으려는 조치로 풀이된다.\n",
      "실제로 한국은행이 최근 발표한 '2021년 3분기 가계신용(잠정)'에 따르면 지난 3분기 말 기준 가계신용 잔액은 전 분기 대비 36조7000억원(2%) 늘어난 1844조9000억원을 기록했다.\n",
      "증가폭은 지난 2분기 대비 3분기 증가분(43조5000억원)보다 소폭 감소했지만, 전년 동월 대비로는 약 54조원 증가했다.\n",
      "특히 가계신용에서 가장 큰 비중을 차지하는 가계대출은 전 분기 대비 약 37조원 늘어난 1744조7000억원을 기록하며 통계 작성 이후 사상 최대치를 또 한 번 경신했다.\n",
      "물론, 3분기 전체가 아닌 지난 8월 기준금리 인상 효과가 반영된 지난 10월 기준 가계부채 증가세는 이전보다 소폭 완화된 모습을 보이기도 했다.\n",
      "지난 10월 말 기준 은행 가계대출은 1057조9000억원으로 전월 대비 5조2000억원 늘어났는데, 이는 지난 8월 대비 9월 증가분(6조4000억원)보다 소폭 축소한 수치였다.\n",
      "가계대출의 가장 큰 비중을 차지하는 주택담보대출은 10월 말 기준 774조5000억원을 기록하며 지난 7월 이후 최저 수준의 전월 대비 증가세(4조7000억원)를 보였다.\n",
      "또, 동 기간 신용대출을 포함한 가계 기타대출 잔액은 전월 말 대비 5000억원 늘어난 282조4000억원을 기록했다.\n",
      "이 역시 8월 대비 9월 증가분(8000억원)보다 다소 감소한 수치였다.\n",
      "이처럼 기준금리 인상에 따른 가계부채 증가세 억제 효과가 조금씩 나타나고 있다는 점을 들어, 이번 금통위가 추가 금리 인상을 결정했다는 분석이다.\n",
      "금융업계의 한 관계자는 \\\"기준금리 추가 인상에 더해 은행권의 대출 조이기 기조는 적어도 내년 상반기까지 이어질 가능성이 높다\\\"며 \\\"내년에도 올해 수준의 가계부채 증가율 관리가 예상되는 만큼 신용대출 증가세는 당분간 둔화할 것으로 보인다\\\"라고 설명했다.\n",
      "이밖에 한국은행은 이번 금리 인상을 통해 소비자물가 상승률이 현재 3%대에서 목표치(2%대)까지 낮아질 것으로 기대하고 있다.\n",
      "그동안 한국은행은 소비자물가 상승률을 낮춰 민간소비 시장의 활성화를 도모하기 위해서는 기준금리를 올려야 한다는 입장을 견지해왔다.\n",
      "제로금리 시대 종료의 여파는? 물론, 제로금리 시대의 마감에 따른 우려의 목소리도 적지 않다.\n",
      "당장 대출 차주들의 이자 부담이 눈덩이처럼 불어날 가능성이 제기된다.\n",
      "지난주(19일) 기준 국내 4대 시중은행(KB국민‧신한‧하나‧우리)의 주택담보대출 금리(고정형 기준)는 연 3.76~5.12% 수준으로 전년 말(2.69%~4.20%) 대비 최하단과 최상단 모두 약 1%p 가량 상승했다.\n",
      "제로금리 시대에서 연 5%를 넘었다는 점을 고려하면, 1% 기준금리가 시장에 반영되는 내년 초에는 연 6%대의 주담대가 등장할 가능성도 매우 높다.\n",
      "금리 인상은 곧 차주들의 이자부담 증가로 이어진다.\n",
      "실제로 한국은행에 따르면 기준금리가 1%에 도달할 경우, 가계의 연간 이자 부담은 전년 말 대비 5조 8000억원 증가(9월 말 기준)하는 것으로 추산했다.\n",
      "또 가계대출 금리가 1%p 오르면 가계의 이자 부담은 12조5000억원 증가할 것이라는 전망도 내놨다.\n",
      "특히 금융업계 내부에선 한은이 공언한 대로 내년에 추가로 금리가 인상돼 최대 1.5% 수준까지 금리가 오를 경우, 내년 가계가 부담해야 할 이자는 약 65~68조원에 달할 것이라는 예측도 나왔다.\n",
      "금융업계의 한 관계자는 데일리임팩트에 \\\"가산금리 상승과 우대금리 축소 기조, 그리고 이번 기준금리 추가 인상으로 시중은행의 대출 금리 상승세도 더욱 가팔라질 것\\\"이라며 \\\"본격적인 금리 상승기에 접어든 만큼, 차주들의 이자 부담은 더욱 커질 수밖에 없다\\\"고 내다봤다.\n",
      "한편, 은행업계뿐 아니라 카드, 보험, 증권 등 여타 금융업계에서도 이번 기준금리 인상의 영향권에 속해 있다.\n",
      "다만 직접적 영향을 받는 은행과는 달리 비교적 영향은 제한적일 것으로 관측된다.\n",
      "우선 보험업계는 이번 기준금리 인상이 긍정적인 영향을 미칠 것으로 보고 있다.\n",
      "금리가 상승하면 보험부채 증가 부담이 감소하고 자산운용 환경이 개선될 수 있다는 것이다.\n",
      "보험업계 관계자는 데일리임팩트에 \\\"금리가 인상되면 일반계좌 상품들의 수익률이 높아지기 때문에 보험회사 입장에서도 수익률 개선의 효과를 보게 된다\\\"며 \\\"변액보험이 핵심인 보험사에는 금리상승은 일정 부분 영향을 미칠 수 있다\\\"고 설명했다.\n",
      "반면, 증권업계는 이번 기준금리 인상이 주식시장의 흐름을 바꿀만한 큰 요인은 아닐 것으로 보고 있다.\n",
      "이번 금리 인상과 관련한 리스크는 이미 증시에 선반영 됐기 때문에, 실제 금리 인상 결정에 따른 영향은 제한적일 수밖에 없다고 분석한다.\n",
      "김영환 NH투자증권 연구원은 \\\"현재 시중금리는 금리인상을 선반영한 것으로 오히려 추후 한국은행이 금리 인상 의지에 대해 톤 조절에 나설 가능성도 배제할 수 없다\\\"며 \\\"이번 기준금리 인상보다는 오히려 미국 금리 상승 압력이 주식시장에 더 큰 영향을 줄 수 있다\\\"고 진단했다.\n",
      "-------------title-------------\n",
      "\\\"수요 늘고 제품값 강세\\\" 세아제강, 2Q 영업익 700% 이상 늘어\n",
      "-------------document-------------\n",
      "삼성전자가 깜짝 실적 행진을 이어갔다.\n",
      "삼성전자는 7일 연결 기준으로 1분기 매출은 77조원, 영업이익은 14조1000억원으로 잠정 집계됐다고 밝혔다.\n",
      "연말 성수기였던 지난해 4분기보다 매출 0.56%, 영업이익 1.66% 증가했다.\n",
      "지난해 1분기와 비교하면 성장세가 더 두드러진다.\n",
      "매출은 17.76%, 영업이익은 무려 50.32% 늘었다.\n",
      "이는 증권가의 전망을 훨씬 웃도는 깜짝 실적이다 금융정보업체 에프앤가이드가 취합한 증권사 전망치 평균(컨센서스)에 따르면, 삼성전자는 올 1분기 매출 75조1454억원, 영업이익 13조1031억원을 기록할 것으로 추정됐다.\n",
      "이에 따라 매출은 역대 분기 최대치를 경신했다.\n",
      "지금까지 분기 최대성적은 지난해 4분기(76조5655억원)이었다.\n",
      "영업이익도 반도체 초호황기였던 2018년 1분기(15조6400억원)에 이어 두 번째로 높았다.\n",
      "전자업계에서 1분기는 신제품 전략을 구상하는 기간이라 비수기로 꼽혀 왔다.\n",
      "더욱이 올해 시장 상황이 썩 좋지 않았다.\n",
      "신종 코로나 바이러스 감염증(코로나19) 장기화로 반도체 수급난이 지속됐다.\n",
      "러시아의 우크라이나 침공으로 공급망 문제가 불거진 가운데 원자재 가격과 물류비가 치솟았다.\n",
      "특히 삼성전자의 기술력을 둘러싼 논란이 동시다발적으로 터졌다.\n",
      "전략 스마트폰인 갤럭시S22 시리즈는 출시 직후 게임 최적화 서비스(GOS)로 곤욕을 치렀고, 반도체 위탁생산(파운드리)는 수율 논란이 제기됐다.\n",
      "이 같은 악재에도 불구하고 삼성전자는 반도체와 스마트폰 사업 양쪽에서 기대 이상의 성적을 거두는 데 성공했다. '위기일수록 강한' 삼성전자의 진면목이 드러났다는 평가다.\n",
      "주력사업인 반도체는 D램과 낸드 가격 하락 폭이 예상보다 적었던 것으로 관측된다.\n",
      "기업용 D램 수요가 견조하게 이어지고 낸드 빅4 업체들의 생산량이 줄어들면서 시장이 우려했던 것보다 가격 하락폭이 크지 않았던 것으로 분석된다.\n",
      "비메모리 분야에서도 수율 문제가 개선되면서 반도체 위탁 생산(파운드리)이 성자세를 유지하는 가운데 지난해 미국 오스틴공장 가동 중단의 기저 효과까지 더해져 호실적을 달성한 것으로 예상된다.\n",
      "반도체업계 관계자는 데일리임팩트에 \\\"반도체 업황에 긍정적인 요인들이 많다\\\"며 \\\"HP, 델, 시스코 등 글로벌 빅테크들의 투자로 수요가 급증했지만 공급이 제한됐다. 게다가 환율 효과까지 더해져 삼성전자가 반도체 부문에서 좋은 성적을 거뒀을 가능성이 높다\\\"고 말했다.\n",
      "반도체 선방 속에 스마트폰 사업도 힘을 보탰다.\n",
      "갤럭시S22가 초반 흥행에 성공하고, 보급형 스마트폰인 갤럭시A 시리즈가 유럽 등지에서 호응을 얻으면서 전체 스마트폰 출하량이 늘어난 것으로 보인다.\n",
      "갤럭시S22는 하루 평균 2만3000여대 이상 팔리며 출시 6주 만에 국내에서만 100만대를 돌파할 전망이다.\n",
      "해외 반응도 심상치 않다.\n",
      "전작보다 20% 이상 판매량이 증가했고, 일부 지역에서는 70%대의 증가율을 기록했다.\n",
      "1분기 매출이 사상 처음으로 70조원을 넘으면서 삼성전자는 매출 300조의 청신호를 켰다.\n",
      "시장에서도 2분기 메모리반도체 가격이 반등하고 반도체 공급난이 풀리면 삼성전자의 실적 성장세가 더욱 클 것이라는 전망을 내놓고 있다.\n",
      "한편, 이날 실적은 한국채택 국제회계기준(IFRS)에 의거해 추정한 결과다.\n",
      "사업부문별 세부 실적은 이달 말 공개된다.\n",
      "이와 관련, 삼성전자는 주주들로부터 미리 문의사항을 받아 실적 발표 콘퍼런스콜에서 답변할 예정이다.\n",
      "-------------title-------------\n",
      "아모레퍼시픽, 젠티스트 투엑스 치약 선봬\n",
      "-------------document-------------\n",
      "아모레퍼시픽의 이너뷰티 브랜드 바이탈뷰티는 체지방 관리와 식이 대사 강화에 집중한 다이어트 건강기능식품 ‘메타그린 슬림업’을 새롭게 출시했다고 20일 밝혔다.\n",
      "메타그린 슬림업은 누적 후기 2만건, 누적 판매 700만개를 돌파한 바이탈뷰티 메타그린의 새로운 라인업이다.\n",
      "다이어트에 핵심인 체지방 감소와 식이 대사 강화에 집중한 제품으로 식사 후 체지방을 잡는 녹차추출물(카테킨)과 식이 관리에 꼭 필요한 비타민C, 판토텐산을 함유했다.\n",
      "녹차추출물은 인체적용시험을 통해 체중, 체지방, 허리둘레 등 균형 잡힌 몸을 위한 핵심이 되는 9가지 신체 지표를 개선함이 확인된 바 있다.\n",
      "판토텐산은 식사로 섭취한 탄수화물·단백질·지방을 에너지로 전환시키는 엔진과도 같은 역할을 해 식이 대사에 꼭 필요한 영양소다.\n",
      "메타그린 슬림업은 카페인 저감화 공정을 거친 녹차추출물만을 사용했기 때문에 카페인 섭취에 부담이 적다.\n",
      "또한 정제를 코팅하기 위한 식품 첨가물 4가지(이산화티타늄, 스테아린산마그네슘, 이산화규소, 결정셀룰로오스)를 사용하지 않고 장용성 코팅 적용으로 위에서 녹지 않아 속 불편감 없이 부드럽게 섭취할 수 있다.\n",
      "한편 바이탈뷰티는 메타그린 슬림업을 출시하며 신규 디지털 광고 영상 및 화보를 공개했다.\n",
      "반복되는 멜로디로 구성된 중독성 있는 배경 음악과 ‘빠진다’는 중의적 표현으로 제품의 특장점을 위트있게 전달한다.\n",
      "-------------title-------------\n",
      "구자학 아워홈 회장 퇴진…경영 일선서 물러나\n",
      "-------------document-------------\n",
      "올해 주총 시즌이 마무리되면 국내 100대 기업의 이사회 내 다양성이 다소 제고될 것으로 예상된다.\n",
      "지난해 3분기 기준으로는 국내 100대 기업 중에서 사외이사 전원이 남성으로만 이뤄진 기업이 70개에 달한다.\n",
      "과반이 훌쩍 넘는 수준이다.\n",
      "하지만 올해 각 기업이 금융감독원에 제출한 주주총회 소집 결의서를 분석한 결과 주총에서 사외이사 선임안이 통과할 경우 100대 기업 중 절반은 이사회에 적어도 1명의 여성 이사가 포함된다.\n",
      "기업분석 전문 한국CXO연구소(소장 오일선)는 '2021년 국내 100대 기업의 여성 사외이사 현황 조사 결과'에서 여성 사외이사가 있는 기업이 절반을 기록했다고 16일 밝혔다.\n",
      "아울러 올해 신규 선임하는 사외이사 중 33%가량이 여성이라는 결과를 도출했다고 발표했다.\n",
      "조사 대상 기업은 매출(개별 및 별도 재무제표 기준) 100대 상장사이고, 작년(2020년 3분기 기준)과 올해 현황을 비교 조사했다.\n",
      "2021년 현황은 각 기업이 최근 금융감독원에 제출한 주주총회 소집 결의서에 공시한 사외이사 선임 여부 등을 참조했다.\n",
      "사외이사는 주로 경영진 업무에 대한 조언이나 전문지식을 제공하고. 회사와 독립적인 지위를 보장받으면서 회사 경영을 감시·감독하는 역할을 수행한다. 100대 기업의 결의서 분석 결과, 재선임 및 신규 선임된 사외이사는 모두 160명이다.\n",
      "이중 63명은 임기가 만료됐으나 올해 재선임 된 경우이고, 97명은 신규 사외이사로 선임된 것으로 파악됐다.\n",
      "새로 선임된 사외이사 97명 중 여성은 31명(32%)이었고, 남성은 66명(68%)으로 우세한 흐름은 바뀌지 않았다.\n",
      "다만 올해는 100대 기업이 3명 중 1명꼴로 여성 사외이사를 선임해 변화의 속도는 빨라졌다.\n",
      "작년까지 활동했던 여성 사외이사는 35명이었는데 이중 7명은 임기만료로 물러난다.\n",
      "나머지 28명만 작년에 이어 올해도 사외이사 타이틀을 이어갈 전망이다.\n",
      "이들 28명과 이번에 새로 선임된 31명을 더하면 올해 총 59명의 여성 사외이사가 회사 경영을 감시·감독하게 된다.\n",
      "이 경우 100대 기업 전체 사외이사 440명 중 여성 비율은 지난해 7.9%에서 2021년 올해는 13.4%로 1년 새 5.6%p 높아진다.\n",
      "최소한 1명의 여성 사회이사를 배치하는 기업도 100곳 중 절반인 50곳으로 늘어난다.\n",
      "여기에 100대 기업 내 여성 사내이사 4명도 포함하면 사내·외이사 중 여성 비율은 올해 8.3%로 소폭 증가한다(남성 비율 91.7%). 지난해에는 전체 사내·외이사 756명 중 여성은 39명이고 비율은 5.2%에를 기록했다.\n",
      "다만 100대 기업의 전체 이사회 구성이 지난해와 올해 모두 남성 비율이 여전히 90% 넘어 압도적으로 높다.\n",
      "아울러 이사회 내 여성 비중이 이만큼 증가하는 것도 주총에서의 사외이사 선임 안건이 모두 순탄하게 통과한다는 전제 아래서다.\n",
      "◆ 신규 선임된 여성 사외이사…MZ세대 여성도 영입됐다 올해 새로 합류하게 될 여성 사외이사들의 특징 중 가장 두드러지는 요소는 '50대, 교수(학계) 출신'이다.\n",
      "신규 선임될 31명 중 18명(58%)은 50대에 속했고, 현직 교수 등 학계 출신이 22명(71%)으로 다수를 이뤘다.\n",
      "학자 출신을 선호하는 추세는 내년에도 이어질 공산이 크다.\n",
      "여성 임원과 사외이사 경력을 가진 후보군이 아직은 적어 전문성이 높은 학자 출신을 영입하려는 경향이 높기 때문이라고 분석된다.\n",
      "여성 사외이사 후보들 중에서도 돋보이는 후보는 최연소 여성 사외이사로 꼽히는 전미영 트렌드코리아컴퍼니 대표이사다.\n",
      "롯데쇼핑은 1981년생으로 'MZ세대'에 속하는 전 대표를 영입했다.\n",
      "또한 키움증권이 사외이사로 선임한 최선화 서울대 경영학교수와 LG유플러스가 선임한 제현주 옐로우독 대표이사도 눈에 띈다.\n",
      "최 교수는 1978년생으로, 제현주 옐로우독 대표이사는 1977생으로 두 사람 모두 45세 이하로 '젊은 피'에 속한다.\n",
      "주요 고위직 출신으로는 대표적으로 포스코 유영숙 사외이사가 꼽힌다.\n",
      "환경부 장관 출신인 유 사외이사는 최근 정밀의학 생명공학기업인 마크로젠 사외이사로도 선임됐다.\n",
      "금호석유화학 이정미 사외이사는 헌법재판관 출신이고, 삼성생명 조배숙 사외이사는 판사 출신이면서 4선 국회의원을 역임한 화려한 경력 보유자다.\n",
      "한화생명 이인실 사외이사는 통계청장을 역임했고, GS건설 조희진 사외이사는 서울동부지방검찰청 검사장 출신이다.\n",
      "그룹별로 살펴보면 100대 기업 중 현대차 그룹 계열사에서만 5명의 여성 사외이사를 가장 많이 배출해 여성의 이사회 진출에 가장 적극적인 것으로 나타났다.\n",
      "현대자동차 이지윤 카이스트 항공우주공학 조교수, 기아 조화순 연세대 정치외교학 교수, 현대모비스 강진아 서울대 협동과정 기술경영경제정책대학원 교수, 현대건설 조혜경 한성대 IT융합공학부 교수, 현대제철 장금주 서울시립대 경영대학 교수가 현대차 그룹에서 이번에 선임한 여성 사외이사들이다.\n",
      "이번 조사와 관련해 오일선 소장은 미디어SR에 \\\"2022년에도 100대 기업에서 150여명의 사외이사가 임기 만료를 앞두고 있어 이중 신규 영입되는 여성 사외이사는 올해보다 더 많이 늘어날 것으로 전망된다\\\"면서 \\\"여성들을 등기임원으로 전면 배치해 기존의 거수기로 상징되는 이사회 문화를 혁파해나가고 투명하고 책임 있게 경영 활동에 참여하게 하려면 사외이사들에게 좀더 많은 기업 정보 등을 제공하는 방안 등도 동반되어야 한다\\\"고 강조했다.\n",
      "한편 2021년 8월부터 국내에서 자산 규모가 2조원 이상인 기업은 여성 사외이사를 1명 이상 두는 것이 사실상 의무화된다.\n",
      "자본시장법 제165조의 20에 따라 별도 기준 자산총계 2조원 이상의 상장사는 전 구성원을 특정 성으로 채우지 않도록 이사회를 구성해야 한다. 2년의 적용 유예기간이 내년 8월에 종료된다.\n",
      "조항과 관련해 이사회를 동일 성별로만 유지하더라도 별도로 처벌이나 불이익이 발생하지 않는다는 점으로 인해 실효성에 의문이 제기되기도 했다.\n",
      "그러나 전문가들은 글로벌 투자자(자금)의 변화로 인해 자연스럽게 이사회 내 성별 다양성이 제고될 것으로 내다보고 있다.\n",
      "2016년 미국의 행동주의 헤지펀드 '아이즈 캐피털'은 나스닥 상장사 보잉고(Boingo)에게 '남성 위주의 이사 구성을 비판하며, 여성 이사 임명을 비롯해 이사진 교체'를 요구했으며 이를 거부하던 보잉고도 결국엔 여성 이사 1명을 선임했다.\n",
      "아울러 세계 3위의 자산운용사인 스테이트스트리트글로벌어드바이저스(SSGA) 역시 지난해 세계 주요국 기업들에 \\\"ESG 기준에 뒤처진 이사회들을 대상으로 적절한 주주 권한을 행사하겠다\\\"고 으름장을 놓았으며, 현재도 전 세계 기업에 여성 임원의 수를 늘릴 것을 촉구하는 '두려움 없는 소녀 캠페인'을 펼치고 있다.\n",
      "SSGA에 따르면 캠페인 시행 2년 만에 1227개 기업 중 329개가 여성 이사를 선임하거나 관련 계획을 수립해 이같은 변화는 지속·확대될 것으로 보인다.\n",
      "-------------title-------------\n",
      "임인년 발렌타인데이 키워드는 '비싸거나 특별하거나'\n",
      "-------------document-------------\n",
      "편의점업계가 밸런타인데이를 앞두고 차별화 상품과 할인 혜택을 쏟아내며 본격적인 마케팅에 돌입했다.\n",
      "3일 CU는 감성 디자인 브랜드 ‘위글위글’, ‘세컨드모닝’과 손잡고 협업 상품 11종을 내놓는다.\n",
      "해당 상품들은 에코백, 파우치 등 재활용 가능한 패키지에 담겨 있으며 스티커, 컵받침 등 굿즈를 동봉해 실용성을 높였다.\n",
      "유기농 우유 브랜드 ‘보령 우유창고’와 말랑카우 젤리를 담은 콜라보 상품 2종을 선보이며, 셀프 사진관 ‘포토시그니처’와 스튜디오 이용 할인권이 동봉된 모둠상자도 출시한다.\n",
      "GS25는 유명 캐릭터 ‘월리’를 중심으로 이모티콘 ‘최고심’, ‘오늘의 짤’, 93년 대전엑스포 마스코트 ‘꿈돌이’, 인기 웹툰 ‘호랑이형님’의 캐릭터 ‘무케’ 등 유명 캐릭터 및 사진 업체 ‘인생네컷’과 손잡고 다양한 밸런타인데이 기획상품들을 선보인다.\n",
      "세븐일레븐은 100여종의 발렌타인데이 선물 상품을 판매한다.\n",
      "앙리마티스 하트 와인을 발렌타인데이 메인상품으로 선보이며 ‘뚱랑이’, ‘잔망루피’, ‘빨간머리앤’ 등의 인기캐릭터와 초콜릿, 씨리얼 등을 함께 구성한 다양한 이색 협업 상품을 준비했다.\n",
      "이마트24는 300여종의 다양한 초콜릿, 캔디 행사상품을 운영한다. 14일까지 밸런타인데이 행사상품을 구매하고 이벤트에 응모한 고객을 대상으로 추첨을 통해 미니벨로 커플 자전거, 조말론 향수, 애플·갤럭시 워치 스트랩, 코닥 폴라로이드 카메라를 선물한다.\n",
      "미니스톱은 13일까지 제휴 카드로 페레로로쉐 3구, 5구 상품을 2개 이상 구매하는 고객들에게 50% 할인 혜택을 제공한다. 28일까지는 크런키초콜릿, 가나초콜릿, 빈츠, 드림카카오용기 등 초콜릿 22품목을 미니스톱멤버십·카카오페이로 결제 시 30% 할인을 제공한다.\n",
      "-------------title-------------\n",
      "동원F&B, 캔디형 건강기능식품 '올리닉 나잇나잇' 출시\n",
      "-------------document-------------\n",
      "동원F&B가 참치 살코기를 정육면체 모양으로 빚어 한입에 간편하게 먹을 수 있는 신개념 참치 HMR(가정간편식) ‘동원참치 큐브’를 출시했다고 21일 밝혔다. ‘동원참치 큐브’는 동원F&B가 자체 개발한 FM공법을 통해 만들어졌다.\n",
      "FM공법은 첨가물을 넣지 않고 카놀라유만을 활용해 참치 살코기를 정육면체로 빚어내는 기술이다.\n",
      "동원F&B의 오랜 참치 가공 노하우와 어묵 제조법 등 다양한 제조 기술을 접목한 공법으로 2013년 국내 특허 등록을 완료했다. ‘동원참치 큐브’는 바로 먹을 수 있는 컵 타입 4종과 덮밥 소스 형태로 뿌려 먹는 파우치 타입 4종으로 구성됐다. ‘동원참치 큐브’ 컵 타입은 다양한 요리에 활용하기 좋은 오리지널 제품을 비롯해 각종 소스에 담겨 있어 밥 반찬이나 간단한 안주로 활용하기 좋은 매콤고추, 볼케이노, 고소로제 등 총 4종으로 구성됐다.\n",
      "컵 용기에 들어 있어 보관과 섭취가 간편하다.\n",
      "특히 오리지널 제품은 조리를 해도 그 형태가 부서지지 않고 그대로 유지돼 샐러드, 카나페 등 간편 요리를 비롯해 찌개 햄이나 두부의 역할까지도 대신할 수 있다. ‘동원참치 큐브’ 파우치 타입은 네모참치와 함께 다양한 채소와 소스가 들어있는 덮밥용 제품이다.\n",
      "전자레인지에 30초만 데워 밥에 바로 부으면 맛있는 참치 덮밥이 완성된다.\n",
      "새송이버섯, 감자, 당근 등 채소들이 큼직하게 썰려있어 참치와 함께 풍부한 식감을 즐길 수 있다.\n",
      "매콤, 불닭, 카레, 짜장 4종으로 구성돼 취향에 따라 즐길 수 있다.\n",
      "동원F&B는 ‘동원참치 큐브’ 출시에 맞춰 삼성전자와 협업을 통해 다음달부터 경품 행사를 진행한다.\n",
      "경품은 취향에 따라 식품, 주류, 화장품 등 다양한 품목을 보관할 수 있는 맞춤형 소형 냉장고 ‘삼성 비스포크 큐브’와 오븐, 전자레인지, 토스트기, 에어프라이어 기능을 합친 신개념 조리기기 ‘삼성 비스포크 큐커’다. ‘삼성 비스포크 큐브’는 ‘동원참치 큐브’ 컵 타입을 보관하기 좋고, ‘삼성 비스포크 큐커’는 ‘동원참치 큐브’ 파우치 타입을 맛있게 데울 수 있다.\n",
      "일반 동원참치 캔 제품을 포함해 ‘동원참치 큐브’를 오프라인 매장에서 2만원 이상 구매하고 제품과 영수증을 함께 촬영한 사진을 카카오톡 채널 ‘동원참치’로 발송하면 참여할 수 있다.\n",
      "참가자 가운데 추첨을 통해 ▲삼성 비스포크 큐브 냉장고(100명) ▲삼성 비스포크 큐커(50명)를 증정한다.\n",
      "동원F&B 관계자는“’동원참치 큐브’는 간편하게 먹을 수 있으면서도 맛있는 음식을 추구하는 MZ세대를 타겟으로 출시한 신개념 참치 HMR 제품”이라며 “외식이 어려운 코로나 시국에 집에서 다양한 참치 요리를 즐길 수 있는 제품”이라고 말했다.\n",
      "-------------title-------------\n",
      "대우조선해양, LNG운반선 1척 추가 수주\n",
      "-------------document-------------\n",
      "탄소배출이 적은 친환경선박의 선두주자는 단연 우리나라 조선소다.\n",
      "일찌감치 액화천연가스(LNG)운반·추진선을 만들면서 경험을 축적한 덕분이다.\n",
      "정부에 따르면 지난해 전 세계 LNG운반선의 90% 가까이를 한국 조선소가 수주했다.\n",
      "지난 2020년 현대삼호중공업이 LNG추진 대형 컨테이너선을 세계 최초로 만들어 선주에게 넘겼는데, 7개월 먼저 수주한 중국 조선사보다 먼저 건조하면서 기술력을 입증하기도 했다.\n",
      "국내 친환경선박 기술개발 최일선에 있는 유병용 한국조선해양 미래기술연구원 에너지기술연구소 전문위원(사진)에게 최근 현황을 들어봤다.\n",
      "-친환경 선박 개발 어디까지 와있나.\n",
      "△LNG 추진기술은 시장에 정착했고 이제는 보다 경제적이고 친환경적이면서도 쉽게 운전할 수 있도록 고도화 연구개발(R&D)이 진행중이다.\n",
      "암모니아 추진은 잠재적인 미래선박 연료로 주목받는데, 2024~2025년 전후로 상용화를 목표로 개발하고 있다.\n",
      "지난해 기본설계를 개발해 선급 승인을 받았고 독성처리, 연료공급시스템, 배기가스 처리 등 핵심기술 실증을 목표로 하고 있다.\n",
      "-LNG 연료로 충분하지 않을까.\n",
      "△현재로선 LNG가 가장 효용적인 게 분명하다.\n",
      "다만 환경규제가 어떻게 바뀌느냐에 따라 언제든 바뀔 수 있다.\n",
      "탄소세가 급등할 수도 있고 법적으로 이산화탄소 배출 자체가 금지된다면 암모니아나 메탄올 효용성이 높아질 것이다.\n",
      "-유럽 등 글로벌 선사가 중요하게 여기는 부분이 있다면. △탄소배출이 얼마나 줄어드는지 개선효과를 중요시한다.\n",
      "선박은 한번 건조하면 최소 20년 이상 운전하기 때문에 친환경기술이 20년을 보장하는 기술이어야 한다.\n",
      "최근 선원관리 인건비가 올라가는 추세라 보수·관리 등 선박운영 비용부담이 적은 것도 중요하다.\n",
      "아무리 친환경 연료라고 해도 안정적인 공급과 가격이 중요하기에 벙커링 인프라가 갖춰졌는지도 신경쓴다.\n",
      "-연료공급 인프라는 개별 선주나 조선사 차원에서 준비하기 쉽지 않을 텐데.\n",
      "△LNG를 2050년까지 주연료로 예상하는 것도 벙커링 인프라가 충분하기 때문이다.\n",
      "선박연료로 널리 쓰이기 위해선 대용량의 물류체계를 갖춰야 한다.\n",
      "암모니아나 메탄올은 아직 산업계에서 대형 인프라가 부족하다.\n",
      "탄소중립 추세에 맞춰 다른 산업계에서도 널리 쓴다면 이와 연계한 선박용 인프라 구축도 속도를 낼 것으로 본다.\n",
      "-------------title-------------\n",
      "\\\"라방으로 만나는 K-뷰티\\\" CJ올리브영, KOTRA 협업 특별 판촉전\n",
      "-------------document-------------\n",
      "따사로운 햇살이 내리쬐는 날씨가 이어지면서 본격적인 봄이 시작된 가운데 백화점 업계도 진정한 봄날을 맞이했다.\n",
      "20일 관련업계에 따르면 롯데·신세계·현대 등 백화점 빅3는 지난 1일부터 16일까지 이어진 봄 정기세일에서 평균 22.8%의 매출 신장률을 기록했다.\n",
      "이 중 가장 높은 매출 신장률을 기록한 곳은 신세계백화점으로 세일 기간 전체 매출이 전년 대비 28.2% 올랐으며 현대백화점(20.1%) 롯데백화점(20%)이 뒤를 이었다.\n",
      "눈에 띄게 매출이 오른 곳은 단연 패션과 뷰티 부문이다.\n",
      "3사 모두 여성 의류 등 패션 부문에서 20% 이상의 매출 신장률을 나타냈다.\n",
      "롯데백화점의 경우 키즈 의류 등 키즈 상품군에 대한 매출이 전년 대비 40% 이상 오르면서 등교 재개에 대한 수요가 크게 반영됐다.\n",
      "마스크로부터의 해방이 예고되면서 팬데믹 기간 부진했던 색조화장품 매출이 크게 올랐다.\n",
      "현대백화점은 색조화장품 매출이 전년 대비 45.1% 증가했다고 밝혔다.\n",
      "현대백화점 관계자는 \\\"방역조치 완화와 엔데믹 전환 기대감으로 마스크 착용 이후 판매에 어려움을 겪던 립스틱과 같은 색조화장품에 대한 판매 호조가 뚜렷하게 나타났다\\\"고 귀띔했다.\n",
      "세일 마지막 주 거리두기 조치 완화 논의가 본격화되면서 야외활동 수요에 따른 아웃도어 부문 성장세도 두드러졌다.\n",
      "신세계백화점은 이번 세일 기간 동안 골프, 캠핑 등 아웃도어 부문에 대한 매출 신장률이 45.3%에 달한다고 밝혔다.\n",
      "신세계백화점은 야외 마스크 착용 의무화 해제 가능성이 높아지면서 아웃도어 부문에 대한 수요가 크게 증대했다고 분석했다.\n",
      "백화점업계는 이번 봄 정기세일 호조에 힘입어 리오프닝 수요를 겨냥한 공격적인 마케팅 활동을 개진할 전망이다.\n",
      "현대백화점은 증가하는 색조 화장품 수요에 맞춰 내달 초 뷰티페어를 계획하고 있다.\n",
      "현대백화점 측은 이번 뷰티페어의 참가 브랜드 수는 지난해 같은 행사보다 약 40% 늘어나 팬데믹 이후 가장 많은 브랜드가 참여하는 행사가 될 것이라고 전했다.\n",
      "롯데백화점은 팬데믹 기간 주춤했던 웨딩 관련 상품 부문에 대한 프로모션을 강화한다.\n",
      "롯데백화점은 22일부터 오는 1일까지 전 지점에서 해외명품, 가전 등 인기 웨딩 브랜드에 대한 대규모 프로모션을 마련했다.\n",
      "엔데믹 기대감에 따라 그간 연기됐던 결혼식을 서두르는 예비부부들이 늘어나면서 이에 따른 수요를 선점하겠다는 전략이다.\n",
      "뷰티 부문에서도 코로나19로 인해 중단했던 시연 행사 등을 재개하면서 고객들과의 접점을 늘린다.\n",
      "롯데백화점은 국내 최초로 발렌티노 뷰티 공식 매장을 오픈하면서 팬데믹 장기화로 진행하지 못한 메이크업 쇼 등 다채로운 행사를 선보인다.\n",
      "다음달 8일까지 매주 주말 전문 메이크업 아티스트의가 진행하는 메이크업 쇼에 참석한 고객들에게 럭키 드로우와 퀴즈 이벤트를 통해 발렌티노 뷰티의 정품 및 샘플 등 풍성한 선물도 제공할 계획이다.\n",
      "롯데백화점 관계자는 데일리임팩트에 \\\"거리두기 조치가 해제되면서 재택근무를 하는 인원이 감소하고 야외 활동 인구가 늘면서 패션의류와 뷰티 상품군에 대한 수요가 계속 증가할 것으로 예상한다\\\"며 \\\"그동안 코로나19로 인해 진행이 어려웠던 집객성 이벤트나 체험형 이벤트, 문화공연 등 고객들이 적극적으로 참여할 수 있는 이벤트를 많이 선보일 계획\\\"이라고 전했다.\n"
     ]
    }
   ],
   "source": [
    "#load validation file\n",
    "val_file_list = glob(os.path.join(cfg['datadir'], 'validation/NonClickbait_Auto/EC/*'))\n",
    "\n",
    "for q_id, doc_idx_list in enumerate(val_token_overlapped_sorted_idx[:10]):\n",
    "    source_file = json.load(open(val_file_list[q_id], \"r\"))\n",
    "    title = source_file['sourceDataInfo']['newsTitle']\n",
    "    \n",
    "    if doc_idx_list[0] == q_id:\n",
    "        doc_idx = doc_idx_list[1]\n",
    "    else:\n",
    "        doc_idx = doc_idx_list[0]\n",
    "    doc_file = json.load(open(val_file_list[doc_idx],\"r\"))\n",
    "    #doc_title = doc_file['sourceDataInfo']['newsTitle']\n",
    "    document = doc_file['sourceDataInfo']['newsContent']\n",
    "    print('-------------title-------------')\n",
    "    print(title)\n",
    "    print('-------------document-------------')\n",
    "    print(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
