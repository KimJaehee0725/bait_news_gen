{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/code/Fake-News-Detection-Dataset')\n",
    "sys.path.append('/workspace/code/Fake-News-Detection-Dataset/detection')\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer, T5TokenizerFast\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import argparse\n",
    "from methods_search import generation\n",
    "import torch\n",
    "import pandas as pd\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoConfig\n",
    "from detection.model import BERT\n",
    "from kobert_transformers import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset \n",
    "# finetuning transformers==4.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaitDataset(Dataset):\n",
    "    def __init__(self, id_list, title_list, body_list, tokenizer):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = 512\n",
    "\n",
    "        self.title_list = title_list\n",
    "        self.body_list = body_list\n",
    "        self.label_list = [0]*len(title_list)\n",
    "        self.id_list = id_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = self.title_list[index] \n",
    "        body = self.body_list[index] \n",
    "        label = self.label_list[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus( # automatically pad first\n",
    "            text = title,\n",
    "            text_pair = body,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        doc = {}\n",
    "        doc['input_ids']=encoding['input_ids'].flatten()\n",
    "        doc['attention_mask']=encoding['attention_mask'].flatten()\n",
    "\n",
    "        return doc, label\n",
    "    \n",
    "def convert_device(inputs: dict, device: str) -> dict:\n",
    "    for k in inputs.keys():\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def evaluate(model, dataloader, device: str = 'cpu'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_score = []\n",
    "    total_preds = []\n",
    "    total_targets = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in tqdm(enumerate(dataloader), desc = 'EVAL : ', total = len(dataloader)):\n",
    "            inputs, targets = convert_device(inputs, device), targets.to(device)\n",
    "            \n",
    "            # predict\n",
    "            outputs = model(**inputs)\n",
    "            outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            \n",
    "            # total loss and acc\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            correct += targets.eq(preds).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "            total_score.extend(outputs.cpu().tolist())\n",
    "            total_preds.extend(preds.cpu().tolist())\n",
    "            total_targets.extend(targets.cpu().tolist())\n",
    "            \n",
    "    metrics = {\n",
    "        'acc' : correct/total\n",
    "    }\n",
    "\n",
    "\n",
    "    return metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/Fake/content_chunking_forward/generated/fake_top3.csv')\n",
    "df = pd.read_csv('../../data/Fake/content_chunking_forward/filtered/fake_top3_90_99.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>original_content</th>\n",
       "      <th>sim_news_id</th>\n",
       "      <th>fake_title</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>sim_news_content</th>\n",
       "      <th>sim_news_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO_M03_417681</td>\n",
       "      <td>정경두 “SLBM 도발은 남북군사합의에 없다”</td>\n",
       "      <td>정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...</td>\n",
       "      <td>PO_M03_115891</td>\n",
       "      <td>정경두 \\\"北 미사일 발사, ‘비밀적 도발' 없다\\\"</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>북한이 순항미사일을 발사한 지 3일 만인 15일 단거리 탄도미사일 2발을 동해상으로...</td>\n",
       "      <td>한국 첫 SLBM 쏜날, 북 탄도미사일 도발</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IS_M10_079706</td>\n",
       "      <td>상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…</td>\n",
       "      <td>올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...</td>\n",
       "      <td>IS_M10_085484</td>\n",
       "      <td>[202020202020202020202020202020202020202020202...</td>\n",
       "      <td>IS</td>\n",
       "      <td>0</td>\n",
       "      <td>최근 성인용 게임으로 위장한 악성코드가 대량으로 유포되고 있어 이용자 주의가 당부된...</td>\n",
       "      <td>\\\"19금 게임인줄\\\" 받고 보니 좀비PC 만드는 악성코드</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         news_id               original_title  \\\n",
       "0  PO_M03_417681    정경두 “SLBM 도발은 남북군사합의에 없다”   \n",
       "1  IS_M10_079706  상반기 사이버 보안 3대 위협, 랜섬웨어 그리고…   \n",
       "\n",
       "                                    original_content    sim_news_id  \\\n",
       "0  정경두 국방부 장관은 2일 국회 국방위원회 국정감사에서 북한의 이날 미사일 발사가 ...  PO_M03_115891   \n",
       "1  올해 상반기 국내외 사이버 보안 위협 특징으로 랜섬웨어가 꼽혔다.\\nPC와 모바일에...  IS_M10_085484   \n",
       "\n",
       "                                          fake_title category  label  \\\n",
       "0                      정경두 \\\"北 미사일 발사, ‘비밀적 도발' 없다\\\"       PO      0   \n",
       "1  [202020202020202020202020202020202020202020202...       IS      0   \n",
       "\n",
       "                                    sim_news_content  \\\n",
       "0  북한이 순항미사일을 발사한 지 3일 만인 15일 단거리 탄도미사일 2발을 동해상으로...   \n",
       "1  최근 성인용 게임으로 위장한 악성코드가 대량으로 유포되고 있어 이용자 주의가 당부된...   \n",
       "\n",
       "                     sim_news_title  \n",
       "0          한국 첫 SLBM 쏜날, 북 탄도미사일 도발  \n",
       "1  \\\"19금 게임인줄\\\" 받고 보니 좀비PC 만드는 악성코드  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "tokenizer = AutoTokenizer.from_pretrained('../finetuning/Models/ke-t5-base-newslike_epoch3')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('../finetuning/Models/ke-t5-base-newslike_epoch3')\n",
    "model = accelerator.prepare(model)\n",
    "sum_model=None,\n",
    "sum_tokenizer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = df.sample(8)\n",
    "\n",
    "prefix = \"summarize: \"\n",
    "batch_size = 8\n",
    "use_metadata = 'content'\n",
    "method = 'chunking'\n",
    "direction = 'forward'\n",
    "\n",
    "generation_config = {'do_sample':True,\n",
    "                     'num_beams':True,\n",
    "                     'min_length':10,\n",
    "                     'max_length':32,\n",
    "                     'temperature':0.8,\n",
    "                     'top_k':30,\n",
    "                     'top_p':0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "generated_title_list = generation(\n",
    "    fake_df['original_title'].to_list(),\n",
    "    fake_df['original_content'].to_list(),\n",
    "    fake_df['sim_news_title'].to_list(),\n",
    "    fake_df['sim_news_content'].to_list(),\n",
    "    prefix,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    accelerator,\n",
    "    sum_model,\n",
    "    sum_tokenizer,\n",
    "    batch_size=batch_size,\n",
    "    use_metadata=use_metadata,\n",
    "    method=method,\n",
    "    direction=direction,\n",
    "    max_input_length=512,\n",
    "    **generation_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 뉴스 제목 :  “지금 우리가 종철이에게 하고픈 이야기 ‘노래’로 표현했죠”\n",
      "유사 뉴스 제목 :  “민중가요의 시대는 갔어도 노래는 계속된다”\n",
      "가짜 뉴스 제목 :  ‘박종철 추모 곡’ 첫 첫 콘서트\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  차벽은 정당하다고? 차벽 없을 때 더 평화로웠는데…\n",
      "유사 뉴스 제목 :  조건부 집회 허용에 민주노총 \\\"생색내기 판결…예정대로 진행\\\"\n",
      "가짜 뉴스 제목 :  \\\"노조노조 집회·시위 자유권 한계\\\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  \\\"코로나19 '집콕'에 부부관계는 멀어지고 형제애는 깊어져\\\"\n",
      "유사 뉴스 제목 :  ‘중국 CIA’ 국가안전부 넘버2, 미국 망명설 확산\n",
      "가짜 뉴스 제목 :  \\\"집콕으로 부부관계 악화\\\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  ‘상위 1%’의 민주주의 사랑법\n",
      "유사 뉴스 제목 :  [2000 책의 흐름] '부자 아빠 가난한 아빠'\n",
      "가짜 뉴스 제목 :  [이슈분석]부자아빠 가난한 아빠, 민주주의 사랑하는 사람\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  한지혜 “언니포스 윤스리”\n",
      "유사 뉴스 제목 :  ‘유퀴즈’ 한지민, 한 살 차이 송혜교의 아역 연기에 매일 울었다\n",
      "가짜 뉴스 제목 :  한지혜 “아기 윤슬양, ‘언니 포스 윤슬양’ 일상 공개[공식]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  GS건설, 대구 수성 첫 자이아파트 6월 중 분양 예정\n",
      "유사 뉴스 제목 :  아이에스동서 '범어 에일린의 뜰' 물난리 소동....\\\"부실시공인지 조사중\\\"\n",
      "가짜 뉴스 제목 :  GS건설, 대구 수성구에 '범어자이' 분양\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  박서준, 손흥민 응원 모습 포착…현지 카메라도 주목\n",
      "유사 뉴스 제목 :  손흥민과 열애 유소영, SNS에 올린 비키니 사진 '깜짝' … S라인 제대로\n",
      "가짜 뉴스 제목 :  박유천·유소연, ‘손흥민 응원' \\\"유소연, 6살 연상연하 특급 커플 탄생\\\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "원본 뉴스 제목 :  고교중퇴 억만장자, 민간인 우주여행 선봉장 되다\n",
      "유사 뉴스 제목 :  스페이스X 우주 관광객 4명, 사흘간 여행 마치고 무사 귀환\n",
      "가짜 뉴스 제목 :  글로벌 첫 민간인 우주여행 '인스퍼레이션3’\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for origin, sim, gen, fake in zip(fake_df['original_title'].to_list(), fake_df['sim_news_title'].to_list(), generated_title_list, fake_df['fake_title'].to_list()):\n",
    "    print('원본 뉴스 제목 : ', origin)\n",
    "    print('유사 뉴스 제목 : ', sim)\n",
    "    # print('생성 뉴스 제목 : ', gen)\n",
    "    print('가짜 뉴스 제목 : ', fake)\n",
    "    print('-------'*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_path = '../../results/content_chunking_forward/best_model.pt'\n",
    "\n",
    "bert_tokenizer = get_tokenizer()\n",
    "\n",
    "model_config = AutoConfig.from_pretrained('monologg/kobert')\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "train_model = BERT( # model.py class\n",
    "    config          = model_config,\n",
    "    num_classes     = 2\n",
    ")\n",
    "train_model.load_state_dict(torch.load(bert_path)) # load pre-trained model\n",
    "train_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVAL : 100%|██████████| 13/13 [00:01<00:00, 10.02it/s]\n",
      "EVAL : 100%|██████████| 13/13 [00:01<00:00, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성 뉴스 정확도 :  0.55\n",
      "가짜 뉴스 정확도 :  0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testset = BaitDataset(\n",
    "    id_list=fake_df['news_id'].to_list(),\n",
    "    title_list=generated_title_list,\n",
    "    body_list=fake_df['original_content'].to_list(),\n",
    "    tokenizer = bert_tokenizer\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size  = 8\n",
    ")\n",
    "\n",
    "baseset = BaitDataset(\n",
    "    id_list=fake_df['news_id'].to_list(),\n",
    "    title_list=fake_df['fake_title'].to_list(),\n",
    "    body_list=fake_df['original_content'].to_list(),\n",
    "    tokenizer = bert_tokenizer\n",
    ")\n",
    "\n",
    "baseloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size  = 8\n",
    ")\n",
    "\n",
    "test_metrics = evaluate(\n",
    "    model        = train_model, \n",
    "    dataloader   = testloader, \n",
    "    device       = device,\n",
    ")\n",
    "\n",
    "base_metrics = evaluate(\n",
    "    model        = train_model, \n",
    "    dataloader   = testloader, \n",
    "    device       = device,\n",
    ")\n",
    "\n",
    "print('생성 뉴스 정확도 : ', test_metrics['acc'])\n",
    "print('가짜 뉴스 정확도 : ', base_metrics['acc'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
